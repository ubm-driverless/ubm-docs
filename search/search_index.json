{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the UBM Driverless Documentation","text":"<p>We are a team of passionate students competing for FSAE (EV-Driverless) and F1tenth competitions.</p>"},{"location":"#about-us","title":"About Us","text":"<p>UniBo Motorsport (UBM) is a student-led team from the University of Bologna. We specialize in designing, building, and racing vehicles.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started with our project, please refer to the Setup Guide. This guide will walk you through the initial setup process, including installing necessary tools and dependencies.</p>"},{"location":"#how-to-add-documentation","title":"How to Add DocumentationLet's drive the future together!","text":"<p>Please refer to the Add Documentation Guide</p>"},{"location":"CPP_PACKAGES/","title":"C++ Packages","text":"<ul> <li>vesc_driver</li> <li>particle_filter_cpp</li> <li>odometry</li> <li>html_visualizer</li> <li>fat_controller_cpp</li> <li>lidar_filter</li> <li>detector_cpp</li> <li>joystick_switch</li> <li>simple_control_algos</li> </ul>"},{"location":"PYTHON_PACKAGES/SUMMARY/","title":"SUMMARY","text":"<ul> <li>ai_controller<ul> <li>ai_controller</li> <li>ai_launch</li> <li>ai_logger</li> </ul> </li> <li>data_collection<ul> <li>data_collection</li> </ul> </li> <li>detector<ul> <li>detector</li> <li>frenet_converter</li> </ul> </li> <li>ekf_py<ul> <li>ekf</li> <li>utils</li> </ul> </li> <li>f1tenth_gym_ros<ul> <li>gym_bridge</li> </ul> </li> <li>particle_filter<ul> <li>particle_filter</li> <li>utils</li> </ul> </li> <li>recorder<ul> <li>recorder</li> </ul> </li> </ul>"},{"location":"PYTHON_PACKAGES/ai_controller/ai_controller/","title":"ai_controller","text":""},{"location":"PYTHON_PACKAGES/ai_controller/ai_controller/#ai_controller.ai_controller.Logger","title":"<code>Logger</code>","text":"<p>Class created for debug purposes.</p>"},{"location":"PYTHON_PACKAGES/ai_controller/ai_controller/#ai_controller.ai_controller.Logger.info","title":"<code>info(msg)</code>","text":"<p>Prints message to terminal in real-time.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <p>message to print. It can be of any type.</p> required"},{"location":"PYTHON_PACKAGES/ai_controller/ai_launch/","title":"ai_launch","text":""},{"location":"PYTHON_PACKAGES/ai_controller/ai_logger/","title":"ai_logger","text":""},{"location":"PYTHON_PACKAGES/ai_controller/ai_logger/#ai_controller.ai_logger.Logger","title":"<code>Logger</code>","text":"<p>Class created for debug purposes.</p>"},{"location":"PYTHON_PACKAGES/ai_controller/ai_logger/#ai_controller.ai_logger.Logger.info","title":"<code>info(msg)</code>","text":"<p>Prints message to terminal in real-time.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <p>message to print. It can be of any type.</p> required"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/","title":"data_collection","text":"<p>Data collection node to collect script that will change car positions.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector","title":"<code>Collector</code>","text":"<p>               Bases: <code>Node</code></p> <p>Collector class to handle data collection and ROS2 node operations.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the Collector instance and set up parameters and subscriptions.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector.add_gaussian_noise","title":"<code>add_gaussian_noise(position, std_dev)</code>","text":"<p>Add Gaussian noise to a position.</p> <p>:param position: The original position as a numpy array. :param std_dev: The standard deviation of the Gaussian noise. :return: The position with added Gaussian noise.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector.calculate_angle","title":"<code>calculate_angle(x1, y1, x2, y2)</code>","text":"<p>Calculate the angle between two points.</p> <p>:param x1: The x-coordinate of the first point. :param y1: The y-coordinate of the first point. :param x2: The x-coordinate of the second point. :param y2: The y-coordinate of the second point. :return: The angle in radians.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector.data_collection_topic_callback","title":"<code>data_collection_topic_callback(msg)</code>","text":"<p>Callback for the data collection subscription.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector.handle_record_action","title":"<code>handle_record_action(recorded_data)</code>","text":"<p>Handle the record action by selecting and publishing positions.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector.load_raceline","title":"<code>load_raceline(raceline_path)</code>","text":"<p>Load the raceline CSV into a DataFrame.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector.respawn_cars_callback","title":"<code>respawn_cars_callback(msg)</code>","text":"<p>Callback for the respawn cars topic subscription.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Collector.select_random_positions","title":"<code>select_random_positions()</code>","text":"<p>Select random positions for the ego and opponent cars on the raceline.</p> <p>:return: A dictionary containing the poses of the ego and opponent cars.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Logger","title":"<code>Logger</code>","text":"<p>Logger class to log messages with different priorities.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Logger.__init__","title":"<code>__init__(logger=None)</code>","text":"<p>Initialize the Logger instance.</p> <p>:param logger: Optional logger instance to use for logging.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Logger.info","title":"<code>info(msg, priority)</code>","text":"<p>Log an info message if the priority is within the verbosity level.</p> <p>:param msg: The message to log. :param priority: The priority level of the message.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.Logger.timed_info","title":"<code>timed_info(msg, priority, timeout=None)</code>","text":"<p>Log an info message with a timeout.</p> <p>:param msg: The message to log. :param priority: The priority level of the message. :param timeout: The timeout duration in seconds.</p>"},{"location":"PYTHON_PACKAGES/data_collection/data_collection/#data_collection.data_collection.main","title":"<code>main(args=None)</code>","text":"<p>Main function to run the data collection node.</p> <p>:param args: Optional arguments to pass to the node :return: None.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/","title":"detector","text":""},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector","title":"<code>Detector</code>","text":"<p>               Bases: <code>Node</code></p> <p>This class implements a ROS node that detects obstacles on the track</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.checkObstacles","title":"<code>checkObstacles(current_obstacles, pointclouds_list)</code>","text":"<p>Deletes obstacles that exceed a maximum size and updates the list of tracked obstacles.</p> <p>Parameters:</p> Name Type Description Default <code>current_obstacles</code> <code>list</code> <p>List of <code>Obstacle</code> objects to be checked.</p> required <code>pointclouds_list</code> <code>list</code> <p>List of point clouds representing obstacles.</p> required"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.clearmarker","title":"<code>clearmarker()</code>","text":"<p>Creates a Marker object with an action to clear a single marker.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.clearmarkers","title":"<code>clearmarkers()</code>","text":"<p>Creates a Marker object with an action to clear markers.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.control_loop","title":"<code>control_loop()</code>","text":"<p>Main control loop of the <code>Detector</code> node. Processes data and performs actions based on lidar scans.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.find_values","title":"<code>find_values(x, file_path)</code>  <code>staticmethod</code>","text":"<p>Finds the nearest x_m and y_m values in a CSV file based on the given x. Args:     x (float): The x-coordinate to find the nearest value for.     file_path (str): Path to the CSV file. Returns:     tuple: (x_m, y_m) of the nearest point in the CSV file.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.get_coords_wrt_wpts","title":"<code>get_coords_wrt_wpts(x_cartesian, y_cartesian)</code>","text":"<p>Finds the closest waypoint and the distance to a given Cartesian coordinate. Args:     x_cartesian (float): X coordinate in Cartesian space.     y_cartesian (float): Y coordinate in Cartesian space. Returns:     tuple: (s, d, idx) where s is the closest s value, d is the distance to the closest waypoint, and idx is the index of the closest waypoint.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.laserPointOnTrack","title":"<code>laserPointOnTrack(s, d)</code>","text":"<p>Checks if a given point (s, d) is on the track. The function considers various conditions:    - car's viewing distance    - track's width    - point's position relative to the track's centerline. Args:     s (float): Frenet-like s-coordinate.     d (float): Frenet-like d-coordinate. Returns:     bool: True if the point is on the track, False otherwise.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.obsPointClouds2obsArray","title":"<code>obsPointClouds2obsArray(objects_pointcloud_list)</code>","text":"<p>Converts a list of point clouds (representing obstacles) into an array of Obstacle objects. Each point cloud is processed to fit a rectangle around the points. Computes the attributes of the Obstacle object: center, size, and orientation.</p> <p>Parameters:</p> Name Type Description Default <code>objects_pointcloud_list</code> <code>list</code> <p>A list of point clouds, each representing a potential obstacle.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of Obstacle objects with computed attributes.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.path_clk","title":"<code>path_clk(msg)</code>","text":"<p>Callback function for receiving raceline data. Processes the data to initialize waypoints and update attributes related to the raceline. Args:     msg (RacelineStamped): The raceline message containing waypoint information.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.pose_clk","title":"<code>pose_clk(msg)</code>","text":"<p>Callback function for receiving pose data. Updates the current pose, computes the car's position relative to waypoints, and calls the control loop. Args:     msg (PoseStamped): The pose message containing the current pose of the car.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.publishCsvRaceline","title":"<code>publishCsvRaceline(x, y)</code>","text":"<p>Publishes a marker representing a point on the raceline.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>The x-coordinate of the raceline point.</p> required <code>y</code> <code>float</code> <p>The y-coordinate of the raceline point.</p> required"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.publishObstaclesMarkers","title":"<code>publishObstaclesMarkers()</code>","text":"<p>Publishes markers for the detected obstacles to visualize them. Each obstacle is visualized as a cube in RViz with its size and orientation.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.publishObstaclesMessage","title":"<code>publishObstaclesMessage()</code>","text":"<p>Publishes detected obstacles as an <code>ObstacleArray</code> message, which includes: - id - start and end points along the s-axis (longitudinal direction) - left and right points along the d-axis (lateral direction) - center points - size - angle (theta) - corner points (1 to 4)</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.quaternion_from_euler","title":"<code>quaternion_from_euler(roll, pitch, yaw)</code>  <code>staticmethod</code>","text":"<p>Converts Euler angles to a quaternion. Args:     roll (float): Roll angle in radians.     pitch (float): Pitch angle in radians.     yaw (float): Yaw angle in radians. Returns:     list: Quaternion [qx, qy, qz, qw].</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.quaternion_to_yaw","title":"<code>quaternion_to_yaw(quat)</code>  <code>staticmethod</code>","text":"<p>Convert quaternion to yaw angle.</p> <p>Parameters:</p> Name Type Description Default <code>quat</code> <p>Quaternion (w, x, y, z) tuple</p> required <p>Returns:</p> Type Description <code>float</code> <p>Yaw angle in radians</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.scan_callback","title":"<code>scan_callback(msg)</code>","text":"<p>Callback function for receiving LaserScan data. Updates the scan attribute with the received message. Args:     msg (LaserScan): The LaserScan message containing scan data.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.scans2ObsPointCloud","title":"<code>scans2ObsPointCloud()</code>","text":"<p>Converts the lidar scans to a 2D PointCloud and segments them into objects. 1) it transforms the scan ranges into a cloud point. 2) it segments the cloud point into smaller point clouds that represent potential objects using an adaptive method. 3) it removes point clouds that are too small, too big, or have their center point not on the track.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of segmented point clouds, each representing a potential object.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Detector.separate_coordinates","title":"<code>separate_coordinates(path)</code>  <code>staticmethod</code>","text":"<p>Extract x and y coordinates from a list of objects, each having a <code>pose</code> attribute.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>list</code> <p>List of objects with <code>pose.position.x</code> and <code>pose.position.y</code></p> required <p>Returns:</p> Type Description <code>(list, list)</code> <p>Tuple of lists containing x and y coordinates</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Logger","title":"<code>Logger</code>","text":"<p>Class added for debug purposes.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Logger.info","title":"<code>info(msg, priority)</code>","text":"<p>Prints message to terminal in real-time.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <p>message to print. It can be of any type.</p> required <code>priority</code> <code>int</code> <p>priority of the message. The lower the value, the higher the priority. If the priority of the message is lower or equal to the verbosity level, the message will be printed.</p> required"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Logger.timed_info","title":"<code>timed_info(msg, priority, timeout=None)</code>","text":"<p>Prints message to terminal if it has not already been printed within <code>DISABLE_PRINT_TIMEOUT</code> seconds.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <p>message to print. It can be of any type.</p> required <code>priority</code> <code>int</code> <p>priority of the message. The lower the value, the higher the priority. If the priority of the message is lower or equal to the verbosity level, the message will be printed.</p> required <code>timeout</code> <code>float</code> <p>time in seconds after which the message will be printed again. If None, <code>timeout</code> will be set to <code>DISABLE_PRINT_TIMEOUT</code>.</p> <code>None</code>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Obstacle","title":"<code>Obstacle</code>","text":"<p>This class implements the properties of the obstacles</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.Obstacle.squaredDist","title":"<code>squaredDist(obstacle)</code>","text":"<p>Calculate the squared distance between this obstacle and another one.</p> <p>Parameters:</p> Name Type Description Default <code>obstacle</code> <p>The other obstacle</p> required <p>Returns:</p> Type Description <p>Squared distance between the centers of the two obstacles</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.main","title":"<code>main(args=None)</code>","text":"<p>Creates an instance of the <code>Detector</code> class, and runs the main loop of the <code>Detector</code> node.</p>"},{"location":"PYTHON_PACKAGES/detector/detector/#detector.detector.normalize_s","title":"<code>normalize_s(x, track_length)</code>","text":"<p>Normalize the given value <code>x</code> with respect to a track length. The function ensures that the normalized value lies within the range of <code>-track_length/2</code> to <code>track_length/2</code> (inside 1 lap).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>value to normalize</p> required <code>track_length</code> <p>length of the track</p> required <p>Returns:</p> Type Description <p>Normalized value</p>"},{"location":"PYTHON_PACKAGES/detector/frenet_converter/","title":"frenet_converter","text":""},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter","title":"<code>FrenetConverter</code>","text":""},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter.__init__","title":"<code>__init__(waypoints_x, waypoints_y)</code>","text":"<p>Initializes the FrenetConverter object with the given waypoints.</p>"},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter.build_raceline","title":"<code>build_raceline()</code>","text":"<p>Builds the spline representation of the raceline.</p>"},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter.check_perpendicular","title":"<code>check_perpendicular(x, y, s, eps_m=0.01)</code>","text":"<p>Checks if the point is perpendicular to the track.</p>"},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter.get_approx_s","title":"<code>get_approx_s(x, y)</code>","text":"<p>Finds the s-coordinate of the given point by finding the nearest waypoint.</p>"},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter.get_cartesian","title":"<code>get_cartesian(s, d)</code>","text":"<p>Convert Frenet coordinates to Cartesian coordinates</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>float</code> <p>longitudinal coordinate</p> required <code>d</code> <code>float</code> <p>lateral coordinate</p> required <p>Returns:</p> Type Description <code>array</code> <p>np.array: [x, y] Cartesian coordinates</p>"},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter.get_derivative","title":"<code>get_derivative(s)</code>","text":"<p>Returns the derivative of the point corresponding to s on the chosen line. </p> <p>Parameters:</p> Name Type Description Default <code>s</code> <p>parameter which is used to evaluate the spline</p> required <code>line</code> <p>argument used to choose the line. Can be 'int', 'mid', 'out'. Default is 'mid'.</p> required <p>Returns:</p> Name Type Description <code>der</code> <code>array</code> <p>dx/ds, dy/ds</p>"},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter.get_frenet","title":"<code>get_frenet(x, y, s=None)</code>","text":"<p>Converts Cartesian coordinates to Frenet coordinates.</p>"},{"location":"PYTHON_PACKAGES/detector/frenet_converter/#detector.frenet_converter.FrenetConverter.get_frenet_coord","title":"<code>get_frenet_coord(x, y, s, eps_m=0.01)</code>","text":"<p>Finds the s-coordinate of the given point, considering the perpendicular projection of the point on the track.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>x-coordinate of the point</p> required <code>y</code> <code>float</code> <p>y-coordinate of the point</p> required <code>s</code> <code>float</code> <p>estimated s-coordinate of the point</p> required <code>eps_m</code> <code>float</code> <p>maximum error tolerance for the projection. Default is 0.01.</p> <code>0.01</code> <p>Returns:</p> Type Description <code>float</code> <p>The s-coordinate of the point on the track.</p>"},{"location":"PYTHON_PACKAGES/ekf_py/ekf/","title":"ekf","text":""},{"location":"PYTHON_PACKAGES/ekf_py/utils/","title":"utils","text":""},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.CircularArray","title":"<code>CircularArray</code>","text":"<p>               Bases: <code>object</code></p> <p>Simple implementation of a circular array. You can append to it any number of times but only \"size\" items will be kept</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.Timer","title":"<code>Timer</code>","text":"<p>Simple helper class to compute the rate at which something is called.</p> <p>\"smoothing\" determines the size of the underlying circular array, which averages out variations in call rate over time.</p> <p>use timer.tick() to record an event use timer.fps() to report the average event rate.</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.angle_to_quaternion","title":"<code>angle_to_quaternion(angle)</code>","text":"<p>Convert an angle in radians into a quaternion message.</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.map_to_world","title":"<code>map_to_world(poses, map_info)</code>","text":"Takes a two dimensional numpy array of poses <p>[[x0,y0,theta0],  [x1,y1,theta1],  [x2,y2,theta2],        ...     ]</p> <p>And converts them from map coordinate space (pixels) to world coordinate space (meters). - Conversion is done in place, so this function does not return anything. - Provide the MapMetaData object from a map message to specify the change in coordinates. - This implements the same computation as map_to_world_slow but vectorized and inlined</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.map_to_world_slow","title":"<code>map_to_world_slow(x, y, t, map_info)</code>","text":"<p>Converts given (x,y,t) coordinates from the coordinate space of the map (pixels) into world coordinates (meters). Provide the MapMetaData object from a map message to specify the change in coordinates. *** Logical, but slow implementation, when you need a lot of coordinate conversions, use the map_to_world function</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.particle_to_pose","title":"<code>particle_to_pose(particle)</code>","text":"<p>Converts a particle in the form [x, y, theta] into a Pose object</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.particles_to_poses","title":"<code>particles_to_poses(particles)</code>","text":"<p>Converts a two dimensional array of particles into an array of Poses.  Particles can be a array like [[x0, y0, theta0], [x1, y1, theta1]...]</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.quaternion_to_angle","title":"<code>quaternion_to_angle(q)</code>","text":"<p>Convert a quaternion message into an angle in radians. The angle represents the yaw. This is not just the z component of the quaternion.</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.rotation_matrix","title":"<code>rotation_matrix(theta)</code>","text":"<p>Creates a rotation matrix for the given angle in radians</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.world_to_map","title":"<code>world_to_map(poses, map_info)</code>","text":"Takes a two dimensional numpy array of poses <p>[[x0,y0,theta0],  [x1,y1,theta1],  [x2,y2,theta2],        ...     ]</p> <p>And converts them from world coordinate space (meters) to world coordinate space (pixels). - Conversion is done in place, so this function does not return anything. - Provide the MapMetaData object from a map message to specify the change in coordinates. - This implements the same computation as world_to_map_slow but vectorized and inlined - You may have to transpose the returned x and y coordinates to directly index a pixel array</p>"},{"location":"PYTHON_PACKAGES/ekf_py/utils/#ekf_py.utils.world_to_map_slow","title":"<code>world_to_map_slow(x, y, t, map_info)</code>","text":"<p>Converts given (x,y,t) coordinates from the coordinate space of the world (meters) into map coordinates (pixels). Provide the MapMetaData object from a map message to specify the change in coordinates. *** Logical, but slow implementation, when you need a lot of coordinate conversions, use the world_to_map function</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/","title":"gym_bridge","text":"<p>ROS2 node that bridges the F1TENTH Gym environment with ROS2.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge","title":"<code>GymBridge</code>","text":"<p>               Bases: <code>Node</code></p> <p>ROS2 node that bridges the F1TENTH Gym environment with ROS2.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the GymBridge node.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.drive_callback","title":"<code>drive_callback(drive_msg)</code>","text":"<p>Callback function for the drive subscription.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.drive_timer_callback","title":"<code>drive_timer_callback()</code>","text":"<p>Callback function for the drive timer subscription.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.ego_reset_callback","title":"<code>ego_reset_callback(pose_msg)</code>","text":"<p>Callback function for the ego reset subscription.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.opp_drive_callback","title":"<code>opp_drive_callback(drive_msg)</code>","text":"<p>Callback function for the opponent drive subscription.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.opp_reset_callback","title":"<code>opp_reset_callback(pose_msg)</code>","text":"<p>Callback function for the opponent reset subscription.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.recording_timer_callback","title":"<code>recording_timer_callback()</code>","text":"<p>Callback function for the recording timer subscription.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.teleop_callback","title":"<code>teleop_callback(twist_msg)</code>","text":"<p>Callback function for the teleop subscription.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.GymBridge.timer_callback","title":"<code>timer_callback()</code>","text":"<p>Callback function for the timer subscription.</p> <p>Publishes scans, odometry and <code>/base_link</code> transform at <code>scan_freq</code>Hz. Publishes lidar and wheel transforms at 1Hz.</p>"},{"location":"PYTHON_PACKAGES/f1tenth_gym_ros/gym_bridge/#f1tenth_gym_ros.gym_bridge.main","title":"<code>main(args=None)</code>","text":"<p>Main function for the GymBridge node.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/","title":"particle_filter","text":""},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler","title":"<code>ParticleFiler</code>","text":"<p>               Bases: <code>Node</code></p> <p>This class implements Monte Carlo Localization based on odometry and a laser scanner.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.MCL","title":"<code>MCL(a, o)</code>","text":"<p>Performs one step of Monte Carlo Localization.     1. resample particle distribution to form the proposal distribution     2. apply the motion model     3. apply the sensor model     4. normalize particle weights</p> <p>This is in the critical path of code execution, so it is optimized for speed.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.clicked_pose","title":"<code>clicked_pose(msg)</code>","text":"<p>Receive pose messages from RViz and initialize the particle distribution in response.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.get_omap","title":"<code>get_omap()</code>","text":"<p>Fetch the occupancy grid map from the map_server instance, and initialize the correct RangeLibc method. Also stores a matrix which indicates the permissible region of the map</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.initialize_global","title":"<code>initialize_global()</code>","text":"<p>Spread the particle distribution over the permissible region of the state space.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.initialize_particles_pose","title":"<code>initialize_particles_pose(pose)</code>","text":"<p>Initialize particles in the general region of the provided pose.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.lidarCB","title":"<code>lidarCB(msg)</code>","text":"<p>Initializes reused buffers, and stores the relevant laser scanner data for later use.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.motion_model","title":"<code>motion_model(proposal_dist, action)</code>","text":"<p>The motion model applies the odometry to the particle distribution. Since there the odometry data is inaccurate, the motion model mixes in gaussian noise to spread out the distribution.</p> <p>Vectorized motion model. Computing the motion model over all particles is thousands of times faster than doing it for each particle individually due to vectorization and reduction in function call overhead</p> <p>TODO this could be better, but it works for now     - fixed random noise is not very realistic     - ackermann model provides bad estimates at high speed</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.odomCB","title":"<code>odomCB(msg)</code>","text":"<p>Store deltas between consecutive odometry messages in the coordinate space of the car.</p> <p>Odometry data is accumulated via dead reckoning, so it is very inaccurate on its own.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.precompute_sensor_model","title":"<code>precompute_sensor_model()</code>","text":"<p>Generate and store a table which represents the sensor model. For each discrete computed range value, this provides the probability of measuring any (discrete) range.</p> <p>This table is indexed by the sensor model at runtime by discretizing the measurements and computed ranges from RangeLibc.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.publish_tf","title":"<code>publish_tf(pose, stamp=None)</code>","text":"<p>Publish a tf for the car. This tells ROS where the car is with respect to the map.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.sensor_model","title":"<code>sensor_model(proposal_dist, obs, weights)</code>","text":"<p>This function computes a probablistic weight for each particle in the proposal distribution. These weights represent how probable each proposed (x,y,theta) pose is given the measured ranges from the lidar scanner.</p> <p>There are 4 different variants using various features of RangeLibc for demonstration purposes. - VAR_REPEAT_ANGLES_EVAL_SENSOR is the most stable, and is very fast. - VAR_NO_EVAL_SENSOR_MODEL directly indexes the precomputed sensor model. This is slow                            but it demonstrates what self.range_method.eval_sensor_model does - VAR_RADIAL_CDDT_OPTIMIZATIONS is only compatible with CDDT or PCDDT, it implments the radial                                 optimizations to CDDT which simultaneously performs ray casting                                 in two directions, reducing the amount of work by roughly a third</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.update","title":"<code>update()</code>","text":"<p>Apply the MCL function to update particle filter state. </p> <p>Ensures the state is correctly initialized, and acquires the state lock before proceeding.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/particle_filter/#particle_filter.particle_filter.ParticleFiler.visualize","title":"<code>visualize()</code>","text":"<p>Publish various visualization messages.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/","title":"utils","text":""},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.CircularArray","title":"<code>CircularArray</code>","text":"<p>               Bases: <code>object</code></p> <p>Simple implementation of a circular array. You can append to it any number of times but only \"size\" items will be kept</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.Timer","title":"<code>Timer</code>","text":"<p>Simple helper class to compute the rate at which something is called.</p> <p>\"smoothing\" determines the size of the underlying circular array, which averages out variations in call rate over time.</p> <p>use timer.tick() to record an event use timer.fps() to report the average event rate.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.angle_to_quaternion","title":"<code>angle_to_quaternion(angle)</code>","text":"<p>Convert an angle in radians into a quaternion message.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.map_to_world","title":"<code>map_to_world(poses, map_info)</code>","text":"Takes a two dimensional numpy array of poses <p>[[x0,y0,theta0],  [x1,y1,theta1],  [x2,y2,theta2],        ...     ]</p> <p>And converts them from map coordinate space (pixels) to world coordinate space (meters). - Conversion is done in place, so this function does not return anything. - Provide the MapMetaData object from a map message to specify the change in coordinates. - This implements the same computation as map_to_world_slow but vectorized and inlined</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.map_to_world_slow","title":"<code>map_to_world_slow(x, y, t, map_info)</code>","text":"<p>Converts given (x,y,t) coordinates from the coordinate space of the map (pixels) into world coordinates (meters). Provide the MapMetaData object from a map message to specify the change in coordinates. *** Logical, but slow implementation, when you need a lot of coordinate conversions, use the map_to_world function</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.particle_to_pose","title":"<code>particle_to_pose(particle)</code>","text":"<p>Converts a particle in the form [x, y, theta] into a Pose object</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.particles_to_poses","title":"<code>particles_to_poses(particles)</code>","text":"<p>Converts a two dimensional array of particles into an array of Poses.  Particles can be a array like [[x0, y0, theta0], [x1, y1, theta1]...]</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.quaternion_to_angle","title":"<code>quaternion_to_angle(q)</code>","text":"<p>Convert a quaternion message into an angle in radians. The angle represents the yaw. This is not just the z component of the quaternion.</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.rotation_matrix","title":"<code>rotation_matrix(theta)</code>","text":"<p>Creates a rotation matrix for the given angle in radians</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.world_to_map","title":"<code>world_to_map(poses, map_info)</code>","text":"Takes a two dimensional numpy array of poses <p>[[x0,y0,theta0],  [x1,y1,theta1],  [x2,y2,theta2],        ...     ]</p> <p>And converts them from world coordinate space (meters) to world coordinate space (pixels). - Conversion is done in place, so this function does not return anything. - Provide the MapMetaData object from a map message to specify the change in coordinates. - This implements the same computation as world_to_map_slow but vectorized and inlined - You may have to transpose the returned x and y coordinates to directly index a pixel array</p>"},{"location":"PYTHON_PACKAGES/particle_filter/utils/#particle_filter.utils.world_to_map_slow","title":"<code>world_to_map_slow(x, y, t, map_info)</code>","text":"<p>Converts given (x,y,t) coordinates from the coordinate space of the world (meters) into map coordinates (pixels). Provide the MapMetaData object from a map message to specify the change in coordinates. *** Logical, but slow implementation, when you need a lot of coordinate conversions, use the world_to_map function</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/","title":"recorder","text":"<p>Recorder 'sink' node: created for AI training purposes.</p> <p>Records data flowing through relevant topics.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder","title":"<code>Recorder</code>","text":"<p>               Bases: <code>Node</code></p> <p>This class implements a ROS node that records driving data.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.__init__","title":"<code>__init__()</code>","text":"<p>Init.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.ackermann_callback","title":"<code>ackermann_callback(msg)</code>","text":"<p>The ackermann message callback, saves last message.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.is_collision_callback","title":"<code>is_collision_callback(msg)</code>","text":"<p>Callback for collision messages.</p> <p>This function processes collision data from the Int32MultiArray message.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.lap_statistics_callback","title":"<code>lap_statistics_callback(msg)</code>","text":"<p>Callback for lap statistics messages.</p> <p>This function process lap statistics data from the LapPerformanceStamped message.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.laser_callback","title":"<code>laser_callback(msg)</code>","text":"<p>The laser message callback, saves last message.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.odom_callback","title":"<code>odom_callback(msg)</code>","text":"<p>The odom message callback, saves last message.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.on_cooldown","title":"<code>on_cooldown()</code>","text":"<p>Returns true if not enough time has passed after last data save.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.record_topic_callback","title":"<code>record_topic_callback(msg)</code>","text":"<p>Callback for record_topic messages.</p> <p>When msg.data is True, it triggers the saving process.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.reset","title":"<code>reset()</code>","text":"<p>Resets the recorder.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.reset_callback","title":"<code>reset_callback(msg)</code>","text":"<p>Callback for reset messages.</p> <p>When msg.data is True, it triggers the reset process.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.save_data","title":"<code>save_data()</code>","text":"<p>Checks if the node is on cooldown and saves the data.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.Recorder.timer_callback","title":"<code>timer_callback(msg)</code>","text":"<p>Callback for the timer.</p> <p>It adds the last recorded messages from the subscribed topics to the list of recordings. It removes the first message of this list if it is outside the recording window.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>Header</code> <p>The timer message.</p> required"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.main","title":"<code>main(args=None)</code>","text":"<p>Main loop.</p> <p>Creates an instance of the <code>Recorder</code> class, and runs the main loop of the <code>Recorder</code> node.</p>"},{"location":"PYTHON_PACKAGES/recorder/recorder/#recorder.recorder.ranges_to_ints","title":"<code>ranges_to_ints(ranges, scale=1000)</code>","text":"<p>Turns an array of floats to an array of integers, scaled by the scale factor.</p> <p>Parameters:</p> Name Type Description Default <code>ranges</code> <code>List[float]</code> <p>The list of float value to convert.</p> required <code>scale</code> <code>int</code> <p>The scale factor applied to each value before rounding.</p> <code>1000</code> <p>Returns:</p> Name Type Description <code>List</code> <code>int</code> <p>The list of rounded values.</p>"},{"location":"guides/","title":"Guides","text":"<p>In this section you can find all the guides and best practices.</p>"},{"location":"guides/ADD_DOCUMENTATION/","title":"How to Add Documentation","text":"<p>Note</p> <p>Please read the guidelines on how to write documentation, refer to UEP 11 - Documentation Guidelines.</p> <p>To contribute new documentation to the website, follow these steps:</p> <ol> <li> <p>Create a Branch </p> <ul> <li>Clone the ubm-docs repository locally.  </li> <li>Create a new branch for your changes.</li> </ul> <pre><code>git clone \"https://github.com/ubm-driverless/ubm-docs.git\"\ngit checkout -b your-branch-name\n</code></pre> </li> <li> <p>Write the Documentation</p> <ul> <li>Write one or more Markdown files (<code>.md</code>) and place them in the most appropriate subfolder within the <code>docs/</code> directory.<ul> <li>If you need to add a subsection:<ol> <li>Create a new subfolder inside an existing subfolder in the <code>docs/</code> directory.</li> <li>Please add your documentation files to this folder. Keep in mind that the first file displayed when the folder is opened on the website will be the file that comes first in alphabetical order, unless an <code>index.md</code> file is present. It is a good practice to include an <code>index.md</code> file that provides an overview of the folder's contents.</li> </ol> </li> <li>If you need to add a new section (a new tab):<ol> <li>Create a new folder inside the <code>docs/</code> directory.</li> <li>Add an <code>index.md</code> file to the new folder. The content of this file will be displayed when the tab is clicked.</li> <li>Add your additional documentation files to the new folder.</li> <li>Update the <code>nav:</code> section in the <code>mkdocs.yaml</code> file (located in the root of the repository) to include the new folder and its files.</li> </ol> </li> </ul> </li> </ul> <p>Tip</p> <p>The files in the website are sorted in alphabetical order, but the title of the page is given by the markdown title of the markdown file  </p> </li> <li> <p>Verify that the website works as expected with your added pages</p> <ol> <li> <p>Create and setup the python virtual environment.</p> <pre><code>python -m venv venv\npip install -r requirements.txt\n</code></pre> </li> <li> <p>Enable the virtual environment (for bash shell)</p> <pre><code>source ./venv/bin/activate\n</code></pre> </li> <li> <p>Modify the <code>PYTHONPATH</code> environment variable for the current terminal session and serve locally the website with mkdocs</p> <pre><code>export PYTHONPATH=\"$PYTHONPATH:$(pwd)/src\"\nmkdocs serve\n</code></pre> </li> </ol> </li> </ol> <p>Tip</p> <p>Serve locally the website while editing the markdown files. You can see the website update each time you save the file. Very useful to verify that it looks as you intend!</p> <p>Note</p> <p>While serving the website on your local machine it is normal that Python Packages and C++ Packages pages are not shown correctly</p> <ol> <li> <p>Submit a Pull Request</p> <ul> <li>Commit your changes and push the branch to the repository:</li> </ul> <pre><code>git add .\ngit commit -m \"Add new documentation for [feature/topic]\"\ngit push origin your-branch-name\n</code></pre> <ul> <li>Open a Pull Request (PR) on GitHub, providing a clear description of your changes.</li> </ul> </li> <li> <p>Deployment </p> <ul> <li>Once the PR is merged into the <code>main</code> branch, an automated workflow will trigger to rebuild and update the website.</li> </ul> </li> </ol>"},{"location":"guides/ADD_DOCUMENTATION/#add-documentation-from-code","title":"Add Documentation from Code","text":"<p>Documentation is automatically generated from code. In order to see updates in the website the <code>ci.yaml</code> workflow needs to be activated.</p>"},{"location":"guides/ADD_DOCUMENTATION/#requisites-for-python","title":"Requisites for Python","text":"<ul> <li>Write Docstrings in the correct format. Refer to UEP 11 for more details.</li> </ul>"},{"location":"guides/ADD_DOCUMENTATION/#requisites-for-c-packages","title":"Requisites for C++ Packages","text":"<ul> <li>Write Docstrings in the correct format. Refer to UEP 11 for more details.</li> <li>Ensure that the package is ROS2-compliant.</li> <li>Place header files in the <code>include</code> directory.</li> <li> <p>In the <code>package.xml</code> file inside the <code>&lt;export&gt;</code> tag make sure to have a link to the rosdoc2.yml confing file.</p> <pre><code>&lt;export&gt;\n    &lt;rosdoc2&gt;../rosdoc2.yml&lt;/rosdoc2&gt; &lt;!--add this, make sure to use the correct relative path --&gt;\n&lt;/export&gt;\n</code></pre> </li> </ul>"},{"location":"guides/F1TENTH_HARDWARE/","title":"F1Tenth Hardware Documentation","text":""},{"location":"guides/F1TENTH_HARDWARE/#disclaimer","title":"Disclaimer","text":"<p>This document is intended to serve as a simple guideline for new members, not as a comprehensive documentation of the entire car's</p> <p>hardware. Therefore, only the most important details will be </p> <p>presented, and it will not include instructions on how to perform a</p> <p>complete teardown of the car.</p> <p>Some basic information will be provided for those who have never used a screwdriver or connected a cable. These instructions will neither be complete nor fully accurate; they are merely intended to ofer suggestions to people with no prior practical experience. </p>"},{"location":"guides/F1TENTH_HARDWARE/#warning","title":"Warning","text":"<p>This document is a work in progress. If you fnd any errors, or if you believe something is missing or unclear, please report them. </p>"},{"location":"guides/F1TENTH_HARDWARE/#basic-guidelines","title":"Basic guidelines","text":""},{"location":"guides/F1TENTH_HARDWARE/#screwdriver","title":"Screwdriver","text":"<p>Make sure to use the correct screwdriver for the job. The main types of screwdrivers, along with their corresponding screws and symbols, are shown in the fgure below. </p> <p></p> <p>If you don't use the right tool, you can damage the screw and, less often, the screwdriver. For example, a slotted screwdriver can be used on a Phillips screw, but it is not the correct tool, and you may damage both. Similarly, you could attempt to use a Torx screwdriver on a hexagon screw, but in this case, only the corners of the screwdriver will make contact with the screw, potentially causing damage to both. Once again, be sure to use the correct tool. </p> <p>Pay attention also to the size of the screwdriver. Always try to use the largest screwdriver that fts properly into the screw (it must not be too large). In this way the contact surface between tool and screw will be maximized. </p> <p>Try to apply the right amount of force (never tight the screw too much)and AVOID SLIPPING between the screw and the screwdriver. Due to wear and to slipping, the screw becomes stripped. </p> <p></p> <p>In this case, it will be very dificult to unscrew it\u2026 In case this happens there are several techniques to remove the screw, but the best thing is to avoid damage and to not use screws that are already damaged. Pay attention please. </p>"},{"location":"guides/F1TENTH_HARDWARE/#battery-charging","title":"Battery charging","text":"<p>Here will be considered one of the two battery charger that the team currently have. It is better than the other because it shows the voltage of the battery. </p> <p>1) Connect the AC cable to the battery charger. The direction does not matter. Then connect the AC cable to the power greed. </p> <p></p> <p>2) At this point the battery charger will emit a sound and the display will turn on. This program should be displayed. </p> <p></p> <p>The battery that the team has are LiPo, 3 Cell, 11.1V, 5000mAh, 50C. The settings you see are for this type of battery and the charging current is set to 3.0A just to be keep the battery safe. In theory, is possible to increase this value but the suggestion is to keep those settings. </p> <p>3) Connect frstly the power cable (yellow one) and the balancing cable (the white one). </p> <p></p> <p></p> <p>As you see, both have a particular form, and it will be hard to connect them wrong. Just pay attention to the white cable: it needs to go on the right of the connector with the black cable on the right and the red on the left. The rightest pin of the charger bust been left empty: that is needed for a 4 Cell battery. </p> <p>4) Now press the start button and keep it pressed until the charger check the battery and ask for a confrmation. </p> <p></p> <p>Then, press again the start button until the charger makes a sound. The charging process will start. </p> <p></p> <p>5) When the charging process will be completed the charger will make a long sound to indicate that the battery is full. At this point you can press stop ad simply detach the battery. If you need to stop the charging earlier, use the stop button and then detach the battery. </p> <p>Warnings: The voltage level of the battery should not go below to 10.5V - 10.0V let\u2019s say (to keep the battery very safe). This because LiPo battery got damaged if they are discharged too much. </p> <p>Moreover, in any case, the car will stop working if the battery voltage will drop under 9.0V (it will be shown why this happens next). For this reason, check the battery voltage frequently by using the right ROS2 topic, through a multi-meter or using the LED we built for this purpose (if it is present and connected). </p>"},{"location":"guides/F1TENTH_HARDWARE/#car-power-connections","title":"Car power connections","text":"<p>1) Power connector of the battery. It will supply the Vesc and, consequently, the motor and the Vesc but not the Jetson. This connection is just an adapter. To disconnect the battery, use this instead of the connection 2 or 3. This because it is simpler and those connectors are ambiguous, in particular the number two, and can happen to connect it in the wrong way. </p> <p>2) Just an adapter. Pay attention to the polarity</p> <p></p> <p>3) Another adapter. The yellow part is the connector of the Vesc</p> <p></p> <p>4) Connection to the motor. It does not matter in which order you connect the three cables. The only \u201cbad\u201d thing that can happen is that the motor (and so the wheel) will start to spin in the wrong direction. To correct this behaviour just fip two of them randomly. This will change the direction of rotation of the magnetic feld of the motor, and it will run in the correct way (you should study electric motor by the way. Beautiful subject if you don\u2019t need to do an exam on it) </p> <p></p> <p>5) Connector for the servo. It goes in \u201cPPM\u201d.</p> <p></p> <p>6) Servo connection, just an adapter. It has a specifc form so there isn\u2019t the risk to attach it in a wrong way </p> <p></p> <p>7) Connector of the battery for the power supply of the Jetson and the LiDAR. It goes to an adapter. The adapter is connected to the power supply board through 8 </p> <p>8) Connector of the adapter to the power board.</p> <p></p> <p>9) And 11) are displayed below. PAY ATTENTION. On the right we have the connector for the Jetson. The red cable goes to 12V and the black cable to GND. On the left we have the power supply of the LiDAR. Brown cable to 12V and blue cable to GND. </p> <p></p> <p>10) Just the connector of the power supply board to the Jetson.</p>"},{"location":"guides/F1TENTH_HARDWARE/#alternative-battery-connection","title":"Alternative battery connection","text":"<p>Take in the connection 7) the cable that goes to the power supply board and attach it to 13). Then, in connection 2) the right connector in the photo needs to be attached to 14). Finally, the left connector of the connection 2) needs to be connected to 12). </p> <p>In this way you can connect the battery just with one cable (the yellow one of the battery). </p> <p>Problem: this connector is damaged, don\u2019t use it. A cable does not make contact in a good manner. </p> <p>Power supply green board </p> <p></p> <p></p> <p>The power supply board can be seen, in frst approximation, as one DC/DC converter and one voltage regulator that are connected to the battery when the switch is turned on. If the switch is on, also the LED turns on. </p> <p>The 12V DC-DC converter is the one that supply both LiDAR and </p> <p>Jetson. It is a switching regulator that keeps the voltage constant at </p> <p>12V if the input voltage (battery voltage) it is between 9V and 36V. For this reason, the car turns of if the voltage of the battery is under 9V. </p> <p>It can provide a maximum power output of 30W, they are suficient for </p> <p>our Jetson and the LiDAR but pay attention if you need to connect </p> <p>other things. In any case, a heat sink placed on it would be nice.</p> <p>The voltage regulator is a dissipative component to regulate the voltage, in this case at 8V. From datasheet it can provide a maximum current of 1A (so 8W is the maximum power). We are not using it but pay attention </p>"},{"location":"guides/F1TENTH_HARDWARE/#car-signal-connections","title":"Car signal connections","text":"<p>1) Micro-Usb connection to the Vesc</p> <p>2) Usb-A connection to the Jetson for the Vesc</p> <p>3) Rj45 connection for the LiDAR</p> <p>4) Antennas connection</p> <p>Tires specifcation and tuning</p>"},{"location":"guides/F1TENTH_HARDWARE/#wheels-and-tire-parameters","title":"WHEELS AND TIRE PARAMETERS","text":"<p>\u2022 12mm hex (VERY IMPORTANT, it is the dimension of the nut of our car to which we need connect the wheel) </p> <p>\u2022 Original ofset parameter not found (It is not important as long as the wheel does not interfere with suspension/steering mechanism) </p> <p>\u2022 Original tire dimensions: 4.3\u201d x 1.7\u2033 (109 mm x 43 mm)</p> <p>\u2022 Changing tire diameter could lead to an increase/decrease of the speed / non-optimal gear ratio. Larger tires increase the fnal gearing (top speed and load are increased) and smaller tires reduce it (better acceleration and fnal gearing is reduced). The better acceleration is caused by a larger force applied on the foor, that means that we are more prone to slipping. Moreover, if we decrease the tire diameter it\u2019s important to check that the base of the car does not touch the foor. </p> <p>In every case if we change the tire diameter, we need to check the Vesc confguration and monitor the condition of the motor (in particular if we increase the diameter and so the load). There is also the option of changing motor gearing but it\u2019s dangerous in my opinion. All the four wheels need to have the same tire dimension, otherwise the smaller tire will slip continuously </p> <p>\u2022 Changing the tire width it\u2019s ok as long as that does not interfere with suspension/steering mechanism </p> <p>\u2022 Original wheel Diameter: 2.2\u201d (56 mm) (outer) 3.0\u201d (76 mm) (inner)) (not really important if we don\u2019t replace only the tire and</p> <p>we WON'T do that, otherwise we need to buy the exact type of tire and also the glue to substitute it </p> <p></p> <p>To dismount the wheels just unscrew these nuts.</p> <p></p>"},{"location":"guides/F1TENTH_HARDWARE/#camber-angle-tuning","title":"CAMBER ANGLE TUNING","text":""},{"location":"guides/F1TENTH_HARDWARE/#camber","title":"Camber","text":"<p>This operation is possible on all the four wheels. If they are brought outward vertically so negative camber (\u201clegs wide\u201d) we have more grip and more friction. An angle between 0.5\u00b0 and 1.5\u00b0 is good. Negative camber improves handling by keeping the tire perpendicular to the road as the car rolls; ensuring that the tire's contact patch is evenly loaded.Without adequate negative camber the tire would load the outer portion of the tire and produce less grip. Adding too much negative camber will reduce the peak tire grip during straight-line acceleration and braking.</p> <p></p>"},{"location":"guides/F1TENTH_HARDWARE/#toe-angle-tuning","title":"TOE ANGLE TUNING","text":"<p>That is only for front wheels. Toe is the measure of how far inward or outward the leading edge of the tire is facing, when viewed from the top. It has a large efect on how the car reacts to steering inputs as well as on tire wear. </p> <p></p> <p>Toe-in is when the leading part of the tire is turned inwards towards the centre of the car. This makes the tires want to push inward, which acts to improve straight line stability of the car as its traveling down the road, particularly at high speed. </p> <p>Toe-out is when the leading part of the tire is turned outwards away from the centre of the car. This makes the tires want to separate from each other. This improves turn-in response considerably, but at the cost of tire wear. </p> <p></p>"},{"location":"guides/F1TENTH_HARDWARE/#lidar-positioning-problem","title":"LiDAR positioning problem","text":"<p>To work correctly, the LiDAR must be positioned with the scan plane parallel to the ground. That is quite intuitive: if the LiDAR scan plane points up-word, it will not see the tubes and the opponent after a certain distance. If it points down-word, it will see the foor. It also must be positioned at the right height for obvious reasons. </p> <p>What is not intuitive is that during accelerations, breaking and turns, due to the suspension system the angle of the plane on which the LiDAR is mounted is modifed. This causes a loss of the wanted alignment of the LiDAR plane with a subsequent wrong measurement. </p> <p>To solve this problem efectively, it is necessary to rearrange the chassis and change the suspension system. For the moment what has been done is to fx the suspension system using cable ties. </p> <p></p> <p></p>"},{"location":"guides/F1TENTH_HARDWARE/#how-to-dismount-the-car","title":"How to dismount the car","text":"<p>In this version only the main passages will be shown. To mount the car back again try to use this passages backword following what you need. Most of the passages are not in a precise order. </p>"},{"location":"guides/F1TENTH_HARDWARE/#before-moving-on-detach-the-battery","title":"BEFORE MOVING ON DETACH THE BATTERY","text":"<p>1) Remove the cover and the LEDs connection. Pay attention during this since the pins of the Nvidia Jetson are not so robust. </p> <p></p> <p></p> <p>2) Detach the Vesc USB cable</p> <p></p> <p>3) Dismount the antennas by rotating them. Pay attention to the \u201cgold\u201d connection and to the cable connected to them. Hold the nut at the side of the cable while you are dismounting the antenna to avoid twisting the cable. </p> <p> </p> <p>Then, turn the other gold nut while you hold the same nut as before. For this is better to a wrench. </p> <p>4) Dismount the battery cable of the Jetson power supply board.Just pull but be careful. </p> <p></p> <p>5) Detach the power cable of the Jetson. The Jetson has classical connector while to detach the cable from the power supply boars a screwdriver is needed (orange circle). When you attach back this cable, PAY ATTENTION TO THE POLARITY! So, you need to connect the red cable to 12V and the black cable to GND</p> <p></p> <p>6) Detach the LiDAR power supply cable. When you attach back this cable, PAY ATTENTION TO THE POLARITY! You need to connect the brown cable to 12V and the blue cable to GND. </p> <p></p> <p>7) Dismount the antenna holder by unscrew the two screws indicated in red. To be sure, hold the other side of the spacers with a hand, indicated in blue while unscrew. </p> <p></p> <p>8) Dismount the green power supply board by unscrew the two indicated screws. </p> <p></p> <p></p> <p>9) Detach the servo power cable. You simply need to pull it but be careful. </p> <p></p> <p>10) Detach the three cables of the motor that are connected to the Vesc. You don\u2019t need to remember the order or how they are attached to the Vesc. </p> <p></p> <p>11) Detach the rj45 cable of the LiDAR form the Jetson</p> <p></p> <p>12) Dismount the Jetson. BE CAREFUL, YOU WILL HAVE AROUND 600 EUROS in your hand with a shipping time of 6 month, IF YOU BREAK IT, THEN YOU ARE DEAD. You need to unscrew these four screws. </p> <p></p> <p>While you are doing this, as usual, hold the spacers to be sure.</p> <p></p> <p>13) Now we need to detach the antenna from the Jetson. PAY ATTENTION. REALLY. ATTENTION PLEASE. Put the Jetson on fat plane in an upside-down position. Use a small fat screwdriver to detach the antenna connector. Put the tip under the cable and carefully arise the tip untill the cable is detached. </p> <p></p> <p>14) Detach the plan from the car. There are three (should be four)screws. The two on the front have a washer. Don\u2019t lose them, they are needed to distribute the force of the screw on higher area and to not damage the black plate. The screw in the back is not really attached, however at this moment there is a small piece of plastic used as a spacer. Don\u2019t lose it. </p> <p></p> <p>15) By put the plane upside down we can see the screw to dismount the LiDAR (Red) and the Vesc (Green) from the plane.</p> <p>We can see also the screws for the spacer of the Jetson (Orange)and the screw for the spacers of the green power board (Blue). It is suggested to dismount them only if needed. </p> <p></p> <p>16) To dismount the wheels just unscrew these nuts.</p> <p></p>"},{"location":"guides/F1TENTH_HARDWARE/#transmission-system-overview","title":"Transmission system overview","text":"<p>Almost all the information that are reported here are being taken directly from the documentation of the Traxxas Slash 4x4. </p> <p>To recap, the motor has a pinion that is connected to the spur gear of the clutch (yes there is a clutch system). The clutch is connected to a transmission bar that gives power to both front and rear wheels. Both front and rear wheels are equipped with a diferential system. </p> <p></p>"},{"location":"guides/F1TENTH_HARDWARE/#removing-the-front-suspension-module","title":"Removing the front suspension module","text":"<ol> <li> <p>Remove the two 4x12 button-head cap screws from the front of the chassis. </p> </li> <li> <p>Remove the two 4x10 button-head cap screws from the top of the chassis. </p> </li> <li> <p>Remove the 3x15 button-head cap screw from the steering link under the chassis. </p> </li> <li> <p>Pull the front suspension assembly away from the chassis.</p> </li> </ol>"},{"location":"guides/F1TENTH_HARDWARE/#removing-the-rear-suspension-module-slipper-clutch-assembly-removal","title":"Removing the rear suspension module (Slipper clutch assembly removal)","text":"<ol> <li> <p>Remove the two 4x12 button-head cap screws from the top of the chassis. </p> </li> <li> <p>Remove the two 4x12 button-head cap screws from the bottom of the chassis. </p> </li> <li> <p>Pull the rear suspension assembly away from the chassis.</p> </li> <li> <p>The slipper clutch assembly can now be removed. </p> </li> </ol>"},{"location":"guides/F1TENTH_HARDWARE/#slipper-clutch","title":"Slipper clutch","text":"<p>Under normal use, the friction material in the slipper clutch should wear very slowly. If the thickness of any one of the slipper clutch pads is 1.8mm or less, the friction disc should be replaced. </p> <p></p>"},{"location":"guides/F1TENTH_HARDWARE/#adjusting-the-slipper-clutch","title":"Adjusting the Slipper Clutch","text":"<p>The model is equipped with an adjustable slipper clutch which is built into the large spur gear. The purpose of the slipper clutch is to regulate the amount of power sent to the wheels to prevent tire spin. When it slips, the slipper clutch makes a high-pitch, whining noise. To adjust the slipper, use the included wrench to hold the adjusting nut and roll the model forward to tighten and reverse to loosen. Place the model </p> <p>on a high-traction surface, such as carpet. Adjust the slipper so that you can hear it slip for approximately two feet from a standing, full throttle start. (Learn more about adjusting the slipper clutch in the sidebar.) </p> <p>To achieve a good starting point for the slipper clutch in this model, remove the slipper gear assembly from your model and tighten the </p> <p></p> <p></p> <p>slipper clutch adjusting nut clockwise until the slipper clutch</p> <p>adjusting spring fully collapses (do not over tighten), and then turn the slipper clutch nut counterclockwise one full turn. </p> <p>Do not run your model with the slipper clutch adjusting spring fully </p> <p>compressed. The minimum recommended slipper clutch setting is</p> <p>1/2 turn counterclockwise from fully compressed.</p>"},{"location":"guides/F1TENTH_HARDWARE/#front-diferential","title":"Front diferential","text":"<ol> <li> <p>Remove the two 3x15mm button-head screws that secure the top bumper mount to the diferential (dif) case. </p> </li> <li> <p>Turn the chassis over and remove the three 4x10mm countersunk screws that hold bumper/skid plate to the bulkhead. The two rear screws do not need to be removed.</p> </li> <li> <p>Slide bumper assembly of of the chassis.</p> </li> <li> <p>Remove 3x15mm button-head screw from dif tie bar.</p> </li> <li> <p>Slide tie bar of truck. </p> </li> <li> <p>Remove two 3x15mm button-head screws from dif cover. Do not remove the two screws that secure the shock tower. </p> </li> <li> <p>Use a 1.5mm hex wrench to remove the two screw pins that hold the driveshaft yokes to the diferential output shafts. Remove the diferential cover and slide the diferential out of the front of the case. </p> </li> <li> <p>To reinstall the diferential, reverse the steps.</p> </li> </ol> <p></p> <p>Rear diferential </p> <ol> <li> <p>Remove the two 3x20mm button-head screws that secure the top bumper mount to dif case. </p> </li> <li> <p>Turn the chassis over and remove the two 3x12mm countersunk crews that hold the bumper/skid plate to the bulkhead. The two front screws do not need to be removed. </p> </li> <li> <p>Remove the 3x20mm button-head screw from the bumper mount and tie bar. </p> </li> <li> <p>Slide bumper assembly of of the chassis. </p> </li> <li> <p>Remove the tie bar from the chassis.</p> </li> <li> <p>Remove the two 3x15mm button-head screws from diferential cover. Do not remove the two screws that secure the shock tower.</p> </li> <li> <p>Remove the diferential cover and slide the diferential out of the front of the case. </p> </li> <li> <p>To reinstall the diferential, reverse the steps.</p> </li> </ol> <p></p>"},{"location":"guides/F1TENTH_HARDWARE/#other-considerations","title":"Other considerations","text":"<p>The diferential is flled with some fuid. In the manual is possible to fnd the procedure to substitute it: </p> <p>Reflling the diferential: </p> <ol> <li> <p>Remove the four 2.5x10mm screws from the diferential case and carefully pull the dif case halves apart. Work over a towel to collect any fuid that drips from the diferential. </p> </li> <li> <p>Drain the fuid from the diferential. You may wish to remove the spider gears from the diferential to make this easier. </p> </li> <li> <p>Place the spider gears back into the dif case (if you removed them). Fill the dif case with fuid until the spider gears are submerged halfway. </p> </li> <li> <p>Rejoin the dif case halves, using care to align the screw holes. Be sure the rubber gasket is in place, or the diferential may leak.</p> </li> <li> <p>Install the 2.5x10mm screws and tighten securely.</p> </li> </ol>"},{"location":"guides/F1TENTH_HARDWARE/#useful-links","title":"Useful links","text":"<p>Slash 4x4 official documentation</p> <p>Traxxas slash tire guide</p>"},{"location":"guides/FOXGLOVE/","title":"About Foxglove","text":"<p>We use Foxglove to visualize the data being published by our ROS nodes.</p> <p>This guide is intended as a series of instructions to quickly setup foxglove for our f1tenth environment, for more detailed information please refer to the official foxglove documentation.</p>"},{"location":"guides/FOXGLOVE/#installation","title":"Installation","text":"<p>To install the Foxglove-studio app follow these instructions, a web app is also available.</p> <p>Create an account and log in.</p>"},{"location":"guides/FOXGLOVE/#connecting-to-the-rosbridge-websocket","title":"Connecting to the Rosbridge websocket","text":"<p>When running the <code>bringup.py</code> launchfile on our f1tenth cars (or the <code>sim.py</code> launchfile in the docker image) a rosbridge websocket will also activate.</p> <p>The websocket's default port is <code>9090</code>, so it's address will be: <pre><code>ws://&lt;car_ip&gt;:9090\n</code></pre> for the cars, and <pre><code>ws://localhost:9090\n</code></pre> for the docker image.</p> <p>Open the Foxglove app and select <code>Open connection...</code>: </p> <p>In the pop-up window select <code>Rosbridge</code> and make sure the address is correct:  Then click <code>Open</code>.</p> <p>You should now be connected to the web socket.</p>"},{"location":"guides/FOXGLOVE/#settings","title":"Settings","text":"<p>The data form the ROS topics can be viewed in the 3D Panel, by selecting the panel you can change its settings in the sidebar on the left (this section is called <code>Panel</code>).</p> <p>For F1tenth set the <code>Display frame</code> to <code>map</code> and hide the transforms in the <code>Transforms</code> section. To view the car model scroll down to <code>Custom layers</code> and click on the three dots to add a <code>URDF</code>, in the <code>URDF</code> you just added select <code>Topic</code> as source and <code>/ego_robot_description</code> in the <code>Topic</code> value. For better visibility set the <code>Color by</code> value of the <code>/scan</code> topic to <code>range</code>.</p>"},{"location":"guides/FOXGLOVE/#panels","title":"Panels","text":"<p>You can change your layout as you see fit, some panels you will likely find useful while working are:</p> <ul> <li><code>Raw messages</code>: displays the content of the messages being published on a topic in real time.</li> <li><code>Topic graph</code>: displays a graph of the ros nodes currently active, like <code>rqt_graph</code></li> <li><code>Publish</code>: allows to publish messages in any of the active topics</li> </ul>"},{"location":"guides/FOXGLOVE/#replaying-ros-bags","title":"Replaying Ros-bags","text":"<p>Foxglove implements an easy way to view the data recorded in a ros-bag file:</p> <p>First, select <code>Open file(s)</code>: </p> <p>Then select the ros-bag file you'd like to view, these are in the <code>.db3</code> format usually.</p> <p>You will now see the usual Foxglove panel with the addition of a playback bar at the bottom that allows to view the ros-bag recording like a video player: </p>"},{"location":"guides/IMAGE_PARSER/","title":"How to Use <code>image_parser.py</code>","text":"<p><code>image_parser.py</code> is a command-line tool designed to assist in creating raceline and detector maps. While the tool automates most of the process, human supervision is required, and it will prompt for manual intervention when necessary.</p>"},{"location":"guides/IMAGE_PARSER/#input-parameters","title":"Input Parameters","text":"<p>To view the full list of input parameters, run:</p> <pre><code>$ image_parser.py -h\n</code></pre> <p>The key parameters are:</p> <ul> <li><code>source-image</code>: The input image to process.</li> <li><code>output-name</code>: The name of the output file.</li> <li><code>level</code>: Controls the processing aggressiveness. Higher values are recommended for low-quality images, while lower values work best for high-quality images. The default value is usually sufficient, as manual intervention is required regardless to check and correct any errors.</li> </ul>"},{"location":"guides/IMAGE_PARSER/#running-the-program","title":"Running the Program","text":"<p>Once executed, the tool will:</p> <ul> <li>Remove all gray pixels.</li> <li>Attempt to fill in all borders.</li> </ul> <p>After processing, the tool will pause and require manual intervention. The user must:</p> <ul> <li>Check if the output is correct.</li> <li>Apply a black background.</li> <li>Correct any errors, if necessary.</li> </ul> <p>The result will be the detector image. Save this image in a separate file accordingly.</p>"},{"location":"guides/IMAGE_PARSER/#important-notice","title":"Important Notice","text":"<p>It is crucial to retain an unmodified copy of the image with the same filename. The tool requires this file to proceed with the next steps.</p>"},{"location":"guides/IMAGE_PARSER/#continuing-the-process","title":"Continuing the Process","text":"<p>Once ready, follow the on-screen instructions to proceed. The tool will then:</p> <ol> <li>Smooth the curves.</li> <li>Pause again for manual intervention.</li> </ol> <p>At this stage, the user must:</p> <ul> <li>Open the image.</li> <li>Apply a black background.</li> <li>Verify the results and fix any errors.</li> </ul> <p>After saving the image and following the final instructions, the process will conclude, producing the raceline image as the final output. If needed, correct the last image</p>"},{"location":"guides/IMAGE_PARSER/#recommended-image-editing-tools","title":"Recommended Image Editing Tools","text":"<p>For simplicity, the following programs are recommended for image modifications:</p> <ul> <li>PAINT (Windows)</li> <li>KOLOURPAINT (GNU/Linux)</li> <li>Equivalent software on macOS</li> </ul> <p>The demonstration video for this tool uses KOLOURPAINT.</p>"},{"location":"guides/INSTALL_CPP_DEPENDENCIES/","title":"How to install GEOS and nanoflann and FLANN for C++","text":""},{"location":"guides/INSTALL_CPP_DEPENDENCIES/#geos","title":"GEOS","text":"<pre><code># To avoid permission issues, install in /usr/local\n$ sudo chown -R ubm:ubm /usr/local  // Not needed if you are root\n\n$ wget https://github.com/libgeos/geos/releases/download/3.12.1/geos-3.12.1.tar.bz2\n\n# Unpack and setup build directory\n$ tar xvfj geos-3.12.1.tar.bz2\n$ cd geos-3.12.1\n$ mkdir _build\n$ cd _build\n\n# Set up the build\n$ cmake \\\n     -DCMAKE_BUILD_TYPE=Release \\\n     -DCMAKE_INSTALL_PREFIX=/usr/local \\\n     ..\n\n# Run the build, test, install\n$ make\n$ ctest\n$ sudo chown -R ubm:ubm /usr/local  // Not needed if you are root\n$ make install\n\n# Add the library path to the environment\n$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\n\n# Comment that line in the file /usr/local/include/geos/geom.h\n# /usr/local/include/geos/geom.h:141:2: warning: #warning *** DEPRECATED: You are using deprecated header geom.h. Please, update your sources according to new layout of GEOS headers and namespaces [-Wcpp]\n</code></pre>"},{"location":"guides/INSTALL_CPP_DEPENDENCIES/#nanoflann","title":"nanoflann","text":"<pre><code># Download the library v1.5.5\n$ cd /home/ubm/repo &amp;&amp; mkdir nanoflann &amp;&amp; cd nanoflann &amp;&amp; mkdir install\n$ git clone https://github.com/jlblancoc/nanoflann.git\n$ mv nanoflann src\n\n# Set up the build\n$ cd src &amp;&amp; mkdir build &amp;&amp; cd build\n$ cmake -DCMAKE_INSTALL_PREFIX=/home/ubm/repo/nanoflann/install ..\n$ make\n$ make install\n</code></pre>"},{"location":"guides/INSTALL_CPP_DEPENDENCIES/#flann","title":"FLANN","text":"<pre><code># Download the master branch of flann-lib/flann\n$ cd /home/ubm/repo &amp;&amp; mkdir flann &amp;&amp; cd flann &amp;&amp; mkdir install\n$ git clone https://github.com/flann-lib/flann.git\n$ mv flann src\n\n# Set up the build\n$ cd src &amp;&amp; mkdir build &amp;&amp; cd build\n$ cmake -DCMAKE_INSTALL_PREFIX=/home/ubm/repo/flann/install -DBUILD_C_BINDINGS=OFF -DBUILD_PYTHON_BINDINGS=OFF -DBUILD_MATLAB_BINDINGS=OFF -DBUILD_EXAMPLES=OFF -DBUILD_TESTS=OFF -DBUILD_DOC=OFF ..\n$ make\n$ make install\n</code></pre>"},{"location":"guides/JETSON_INFO/","title":"Philly's Jetson Xavier NX info","text":""},{"location":"guides/JETSON_INFO/#commands-outputs","title":"Commands' outputs","text":""},{"location":"guides/JETSON_INFO/#l4t","title":"L4T","text":"<p>L4T (Linux 4 Tegra) version <pre><code>$ head -n 1 /etc/nv_tegra_release\n</code></pre> Output: <code># R35 (release), REVISION: 4.1, GCID: 33958178, BOARD: t186ref, EABI: aarch64, DATE: Tue Aug  1 19:57:35 UTC 2023</code></p> <p>Our L4T version is 35.4.1</p>"},{"location":"guides/JETSON_INFO/#jetson-io","title":"Jetson-IO","text":"<p>How to run Jetson-IO <pre><code>sudo /opt/nvidia/jetson-io/jetson-io.py\n</code></pre></p>"},{"location":"guides/JETSON_INFO/#jetson-gpio-pins","title":"Jetson GPIO pins","text":"<ul> <li>pin 2 -&gt; + power supply (5V) -&gt;  black cable</li> <li>pin 6 -&gt; Ground (0V) -&gt; brown cable</li> <li>pin 29 -&gt; white led -&gt; red / white cable</li> <li>pin 31 -&gt; blue led -&gt; blue cable</li> <li>pin 32 -&gt; yellow  led -&gt; yellow cable</li> <li>pin 33 -&gt; green led -&gt; green cable</li> </ul>"},{"location":"guides/JETSON_INFO/#useful-links","title":"Useful links","text":"<ul> <li>Jetson Xavier NX developer kit user guide</li> <li>Jetson Linux board support package</li> <li>Jetson Linux 35.4.1 GA Developer guide</li> <li>Jetson gpio repository</li> <li>Jetson Xavier NX pin layout</li> </ul>"},{"location":"guides/LINTING/","title":"Linting","text":""},{"location":"guides/LINTING/#c-linting","title":"C++ Linting","text":"<p>To ensure that your C++ code follows our coding conventions and guidelines, run the <code>clang-tidy</code> linting tool by following these instructions:</p> <ol> <li>Open a shell in the docker container, refer to the setup guide for instructions.</li> <li>Build the ros2 workspace with the following command:     <pre><code>colcon build --cmake-args -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\n</code></pre>     this will generate the <code>compile_commands.json</code> file</li> <li>run     <pre><code>clang-tidy -p ~/f1tenth_ws/build/compile_commands.json ~/repo/path/to/source\n</code></pre></li> <li>Read the output of the command and make sure that no errors were found.</li> </ol>"},{"location":"guides/LINTING/#python-linting","title":"Python Linting","text":"<p>To ensure that your Python code follows our coding conventions and guidelines, run the <code>ruff</code> linting tool by following these instructions:</p> <ol> <li>Open a shell in the docker container, refer to the setup guide for instructions.</li> <li>run     <pre><code>cd /home/ubm/repo\nruff check path/to/source\n</code></pre></li> <li>Read the output of the command and make sure that no errors were found.</li> </ol>"},{"location":"guides/LINTING/#automated-formatting","title":"Automated formatting","text":"<p>Both <code>clang-tidy</code> and <code>ruff</code> can format the code so that it follows our rules.</p> <p>Warning</p> <p>Not all rules can be enforced automatically and using this functionality is often not enough for the code to be valid.</p> <p>For <code>ruff</code> add the <code>--fix</code> flag: <pre><code>ruff check --fix /path/to/source\n</code></pre></p> <p>For <code>clang-tidy</code> add the <code>--fix</code> flag: <pre><code>clang-tidy -p ~/f1tenth_ws/build/compile_commands.json --fix ~/repo/path/to/source\n</code></pre></p>"},{"location":"guides/MODEM_INTERNET_CONNECTION/","title":"How to connect to router to the internet using USB tethering","text":"<p>The router (TP-Link TP-W8970 v1) runs the latest release of openwrt. This allows us to install packets needeed for the RNDIS protocol, used in USB tethering (<code>kmod-usb-net-rndis</code>) and eventually other packets that might be needed in the future for other vendors' USB tethering implementation (like Huawei phones or iPhones).</p>"},{"location":"guides/MODEM_INTERNET_CONNECTION/#from-and-android-phone","title":"From and android phone","text":"<p>The setup should be plug-and-play:   1. Connect your phone with a USB-C to USB-A cable to the USB1 port of the router (the one closest to the ethernet ports).   2. On your phone, there should a notification saying \"Cable connect for charging, tap to change\". Tap the notification. A menu should appear and you should select \"USB Tethering\" from the list. This step might look different on some usb phones with modified versions of android (Samsung, Xiaomi, Oppo): in this case refer to the manufacturer's instructions on how to enable USB tethering.   3. After some seconds, internet should work for every device connected to the UBM wifi network.</p> <p>If after a minute or so the internet is not working, check that you have done the following:  - You have connected the phone in the USB1 port, not USB2  - You have properly selected the usb tethering option from the connection settings on you phone.</p> <p>To check the latter you could try to log in the router LuCi web-ui:   1. Make sure you are connected to the UBM wifi.  2. Open a browser and visit the ip <code>192.168.1.1</code>  3. Log in using the credentials <code>root</code> and <code>[REDACTED]</code>. The LuCi overview page should appear (it might be useful in other situations, for example to list all devices connected to the wifi).  4. Head over the <code>Network -&gt; Interfaces</code> tab at the top right.  5. If the interface <code>usb0</code> shows no <code>IPv4</code> address, no <code>TX</code> or <code>RX</code> data, that means that you have not correctly enabled USB tethering on your android phone or you don't have a phone that uses the RNDIS protocol.</p>"},{"location":"guides/MODEM_INTERNET_CONNECTION/#from-an-iphoneother-phone-not-using-the-rndis-protocol","title":"From an iPhone/other phone not using the RNDIS protocol","text":"<p>This setup has not been tested. You should refer to the openwrt documentation and update this document if you get a working connection.</p>"},{"location":"guides/MODEM_INTERNET_CONNECTION/#how-to-connect-the-router-to-the-internet-by-connecting-the-router-itself-to-a-local-wifi","title":"How to connect the router to the internet by connecting the router itself to a local wifi","text":"<p>It is possible to connect the router to anoher wifi network and use that as an uplink internet connection. This process is more involved and requires a more complicated setup, since the router's subnet and the uplink wifi's subnet must be different (i.e. you can't connect to wifi networks using a <code>192.168.1.0/24</code> subnet because this is the one that the UBM router uses). Changing subnet is not recommended since the cars are supposed to have static ip addresses (<code>192.168.1.2</code> for philly, <code>192.168.1.3</code> for ben).</p> <p>Note that it is not possible to carry out this procedure with ALMAWIFI because it blocks any attempt of sub-NATting the network.</p> <p>If you wish to continue with this, make sure to have a local backup of the router configuration before proceeding. Once you do, you should follow the tutorial at the openwrt documentation</p>"},{"location":"guides/RACELINE_ENV/","title":"Raceline virtual environment","text":"<p>To run the scripts to create the raceline you will need to create a python virtual environment.</p> <p>You will need a working python installation &gt;= 3.8 and it's respective <code>venv</code> package.</p> <ol> <li>Navigate to the <code>raceline</code> directory of the <code>ubm-f1tenth</code> repo</li> <li>run <code>python3 -m venv &lt;path-to-venv&gt;</code>, the path to the virtual environment can be any path, if you don't know where to put it use <code>raceline/.venv</code>. Make sure to remember this path.</li> <li>Activate the environment:<ul> <li>In bash: <code>source &lt;path-to-venv&gt;/bin/activate</code></li> <li>In powershell: <code>&lt;path-to-venv&gt;/Scripts/Activate.ps1</code></li> </ul> </li> <li>Install the required packages: <code>pip install -r requirements.txt</code></li> </ol> <p>Now you can run the raceline scripts, but you need to activate the environment again every time you restart your shell to do so.</p>"},{"location":"guides/ROS_PACKAGE/","title":"Guide for creating a ROS2 package","text":""},{"location":"guides/ROS_PACKAGE/#prerequisites","title":"Prerequisites","text":"<ul> <li>Having already created a ROS2 workspace</li> </ul>"},{"location":"guides/ROS_PACKAGE/#guide","title":"Guide","text":"<ul> <li>Open a terminal and <code>cd</code> into the workspace folder</li> <li>Source ROS2</li> <li>Execute the following command: <pre><code>ros2 pkg create --build-type ament_cmake &lt;package_name&gt;\n</code></pre> With <code>&lt;package_name&gt;</code> the actual package name.</li> </ul>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/","title":"From 0 to Working Car","text":"<p>In this step by step tutorial I will inlustrate you how to setup all our working environment.</p>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#hardware-list","title":"Hardware List","text":"<ul> <li>Jetson Xavier NX Developer Kit</li> <li>SD card &gt; 6 GB</li> </ul>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#download-card-image","title":"Download Card Image","text":"<ol> <li>Go to the official NVIDIA download page </li> <li>Click On Jetson </li> <li>Inside Filter... search for: <code>Jetson Xavier NX Developer Kit SD Card Image</code> </li> <li>Download the last version</li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#flash-the-image-on-the-sd","title":"Flash the Image on the SD","text":"<ol> <li>Completely format the sd card. Remove any previuosly present partition. </li> <li>From the official Balena Etcher website download it. </li> <li>Run Balena Etcher on Linux:<ul> <li>Unzip the downloaded file</li> <li>Go inside:     <code>balenaEtcher-linux-x64-*.**.**/balenaEtcher-linux-x64</code></li> <li>Double click on <code>balena-etcher</code> runnable</li> </ul> </li> <li>Select the previuosly downloaded image and the wanted SD card and run it</li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-run-the-jetson","title":"Let's run the Jetson","text":"<ol> <li>Attach to the jetson:<ul> <li>Monitor</li> <li>Keyboard</li> <li>Mouse</li> </ul> </li> </ol> <p> 2. Insert the SD card inside the Jetson.  3. Power on the Jetson with a [9; 20] V input. A green led will turn on.  4. The jetson should automatically select SD as boot device, if not you can force it with F11 while starting. Anyway if not probably something wrong while flashing the SD. After the first boot you will end up with: </p>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-set-up-the-jetson","title":"Let's Set-Up The Jetson","text":"<ol> <li>Accept all the licenses</li> <li>Put English as first Language</li> <li>Italian as keyboard layout</li> <li>Rome as time zone</li> <li>Add a user:<ul> <li>username: <code>ubm</code></li> <li>computer_name: <code>ubm-&lt;name_of_the_car&gt;</code></li> <li>password: The usual one</li> <li>Automatic Log in setted On</li> </ul> </li> </ol> <p> 6. The Jetson is ready: </p>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-format-the-ssd","title":"Let's format the SSD","text":"<ol> <li>Search for Disk App. </li> <li>Select the 500GB SSD and from th top right corner three dots select format. </li> <li>Format it leaving averything as default. </li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-move-the-root-to-the-ssd","title":"Let's move the root to the SSD","text":"<ol> <li>Open a Terminal</li> <li><code>cd ~/Downloads</code></li> <li><code>git clone https://github.com/jetsonhacks/rootOnNVMe.git</code></li> <li><code>cd rootOnNVMe</code></li> <li><code>./copy-rootfs-ssd.sh</code> </li> <li><code>./setup-service.sh</code> </li> <li><code>sudo reboot now</code></li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-update-all-the-packages","title":"Let's Update all the Packages","text":"<ol> <li>Open a Terminal</li> <li><code>sudo apt update</code></li> <li><code>sudo apt upgrade</code></li> <li><code>sudo reboot now</code></li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-create-a-swapfile","title":"Let's create a Swapfile","text":"<ol> <li><code>sudo fallocate -l 4G /var/swapfile</code></li> <li><code>sudo chmod 600 /var/swapfile</code></li> <li><code>sudo mkswap /var/swapfile</code></li> <li><code>sudo swapon /var/swapfile</code></li> <li><code>sudo bash -c 'echo \"/var/swapfile swap swap defaults 0 0\" &gt;&gt; /etc/fstab'</code></li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-install-some-basic-software","title":"Let's Install some Basic Software","text":"<ol> <li><code>sudo apt install nano python3.8-full python3-pip tree</code></li> <li><code>sudo pip3 install -U jetson-stats</code></li> <li><code>sudo reboot now</code></li> <li>Now if you run <code>jtop</code>:</li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-add-udev-rules","title":"Let's add udev rules","text":"<ol> <li><code>sudo -s</code></li> <li><code>echo 'KERNEL==\"ttyACM[0-9]*\", ACTION==\"add\", ATTRS{idVendor}==\"15d1\", MODE=\"0666\", GROUP=\"dialout\", SYMLINK+=\"sensors/hokuyo\"' &gt;&gt; /etc/udev/rules.d/99-hokuyo.rules</code></li> <li><code>echo 'KERNEL==\"ttyACM[0-9]*\", ACTION==\"add\", ATTRS{idVendor}==\"0483\", ATTRS{idProduct}==\"5740\", MODE=\"0666\", GROUP=\"dialout\", SYMLINK+=\"sensors/vesc\"' &gt;&gt; /etc/udev/rules.d/99-vesc.rules</code></li> <li><code>sudo udevadm control --reload-rules</code></li> <li><code>sudo udevadm trigger</code></li> <li><code>sudo reboot now</code></li> <li>Check that inside /dev/sensors there is vesc</li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-install-ros2-foxy","title":"Let's Install ROS2 foxy","text":"<ol> <li><code>sudo locale-gen en_US en_US.UTF-8</code></li> <li><code>sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8</code></li> <li><code>export LANG=en_US.UTF-8</code></li> <li><code>sudo apt update &amp;&amp; sudo apt install curl -y</code></li> <li><code>sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg</code></li> <li><code>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null</code></li> <li><code>sudo apt update</code></li> <li><code>sudo apt upgrade</code></li> <li><code>sudo apt install ros-foxy-desktop python3-argcomplete</code></li> <li><code>sudo apt install ros-dev-tools</code> Let's try if ros2 is working:</li> <li><code>source /opt/ros/foxy/setup.bash</code></li> <li><code>ros2 run demo_nodes_cpp talker</code> Expected Output: <pre><code>ubm@ubm-bilbo:~$ ros2 run demo_nodes_cpp talker\n[INFO] [1732365939.572103752] [talker]: Publishing: 'Hello World: 1'\n[INFO] [1732365940.571954330] [talker]: Publishing: 'Hello World: 2'\n[INFO] [1732365941.571874272] [talker]: Publishing: 'Hello World: 3'\n[INFO] [1732365942.571906233] [talker]: Publishing: 'Hello World: 4'\n</code></pre></li> <li><code>sudo apt install python3-colcon-common-extensions</code></li> <li><code>sudo apt install python3-bloom python3-rosdep fakeroot debhelper dh-python</code></li> <li><code>sudo rosdep init</code></li> <li><code>rosdep update</code> <pre><code>reading in sources list data from /etc/ros/rosdep/sources.list.d\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/osx-homebrew.yaml\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/base.yaml\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/python.yaml\nHit https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/ruby.yaml\nHit https://raw.githubusercontent.com/ros/rosdistro/master/releases/fuerte.yaml\nQuery rosdistro index https://raw.githubusercontent.com/ros/rosdistro/master/index-v4.yaml\nSkip end-of-life distro \"ardent\"\nSkip end-of-life distro \"bouncy\"\nSkip end-of-life distro \"crystal\"\nSkip end-of-life distro \"dashing\"\nSkip end-of-life distro \"eloquent\"\nSkip end-of-life distro \"foxy\"\nSkip end-of-life distro \"galactic\"\nSkip end-of-life distro \"groovy\"\nAdd distro \"humble\"\nSkip end-of-life distro \"hydro\"\nSkip end-of-life distro \"indigo\"\nAdd distro \"iron\"\nSkip end-of-life distro \"jade\"\nAdd distro \"jazzy\"\nSkip end-of-life distro \"kinetic\"\nSkip end-of-life distro \"lunar\"\nSkip end-of-life distro \"melodic\"\nAdd distro \"noetic\"\nAdd distro \"rolling\"\nupdated cache in /home/ubm/.ros/rosdep/sources.cache\n</code></pre></li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-create-and-set-up-our-workspace","title":"Let's Create and Set-Up our Workspace","text":"<ol> <li><code>cd $HOME</code></li> <li><code>rm -rf Music Pictures Public Templates Videos Documents</code></li> <li><code>sudo usermod -aG input ubm</code></li> <li><code>mkdir Software</code></li> <li><code>mkdir -p f1tenth_ws/src</code></li> <li><code>cd f1tenth_ws</code></li> <li><code>colcon build</code> <pre><code>ubm@ubm-bilbo:~/f1tenth_ws$ colcon build\n\nSummary: 0 packages finished [1.11s]\n</code></pre></li> <li><code>ssh-keygen</code> Just press enter and leave everything as default <pre><code>Generating public/private rsa key pair.\nEnter file in which to save the key (/home/ubm/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /home/ubm/.ssh/id_rsa\nYour public key has been saved in /home/ubm/.ssh/id_rsa.pub\nThe key fingerprint is:\nSHA256:sdmSu2w/krGwt23PJB9jO0bYyATguRf+6u1x7d+Xq3U ubm@ubm-bilbo\nThe key's randomart image is:\n+---[RSA 3072]----+\n|      ..         |\n|     . ..        |\n|      o o.       |\n|       o B.      |\n|      . So.+     |\n|      ...++ o.   |\n|       o.++.* ..E|\n|      ..*=oOo=..+|\n|       +**=+=ooo=|\n+----[SHA256]-----+\n</code></pre></li> <li><code>cat ~/.ssh/id_rsa.pub</code> <pre><code>ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDN7+Bvuoxp3m94JyjrbjC4HytEGS2a4Jpb3GAvC5NG+8lfm9mrLDdzY/dxlV1mpm56WNK/TLJOwCOcN/fg3PWWbqsrY+sosUtD8auAQs66QiooLDeN2fOoU6oDCLvLpLO6ozIG/ZgeG18nTqcNZR66LQJW3/gsk8w9nkSnii0/dsyF7K5X33/x8R7HecAnT6H2fI10avOH9FkF39g+7L0Ycr2Q7r22LQ/2CSazYLqSb762oExGJ/YdhYxFYmgzQ5Jb54GDdYoghv54zYGEb5ubeVuFnkAtLeGPzANdX0r8rwsn2aZEMNz01E3gr8GCccVa0xApIYUUAGD3QHuw0JALu3o0aRE3CHiFRCJb6hx23qAf872oWKHay/HdwPqw/maVNa2bdYxW70G7jsAvH3hbh0dG73Nro+WQdF38VoxUYYZ1+yTf1QetQSZ/3o/5X+7lCdbfoDygYJcVAuEm2RvTgmK0Epcyq1psEgNd0wsQzKXCeKOnoCk7V1qpWeJ1IyM= ubm@ubm-bilbo\n</code></pre></li> <li>Copy the output on the SSH and GPG keys of the github ubm-device account. Ask for the credentials.</li> <li><code>cd ~/</code></li> <li><code>git clone git@github.com:ubm-driverless/ubm-f1tenth.git repo</code></li> <li><code>cat ~/repo/updated_bashrc.bash &gt;&gt; ~/.bashrc</code></li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-build-f1tenth_system","title":"Let's Build f1tenth_system","text":"<ol> <li><code>ln -s /home/ubm/repo/f1tenth_system/ /home/ubm/f1tenth_ws/src/</code></li> <li><code>cd /home/ubm/f1tenth_ws/src/</code></li> <li><code>git clone https://github.com/f1tenth/ackermann_mux.git</code></li> <li><code>cd /home/ubm/f1tenth_ws</code></li> <li><code>rosdep update --rosdistro=\"foxy\"</code></li> <li><code>rosdep install --from-paths src -i -y</code></li> <li><code>colcon build</code></li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-install-vnc","title":"Let's Install Vnc","text":"<ol> <li><code>sudo apt install Xvfb x11vnc lxsession</code></li> <li><code>sudo nano /etc/systemd/system/vnc.service</code></li> <li>Write inside the file: <pre><code>[Unit]\nDescription=Start Xvfb, LXDE, and x11vnc server\nAfter=network.target graphical.target\nWants=network.target graphical.target\n\n[Service]\nType=forking\nEnvironment=DISPLAY=:99\nExecStart=/bin/bash -c \"Xvfb :99 -screen 0 1024x768x24 &amp; echo $! &gt; /tmp/xvfb.pid; lxsession &amp; echo $! &gt; /tmp/lxsession.pid; x11vnc -display :99 -forever -nopw -xkb &amp; echo $! &gt; /tmp/x11vnc.pid\"\nExecStop=/bin/bash -c \"kill -9 $(cat /tmp/xvfb.pid) $(cat /tmp/lxsession.pid) $(cat /tmp/x11vnc.pid)\"\nPIDFile=/tmp/xvfb.pid\nRestart=always\nUser=ubm\nWorkingDirectory=/home/ubm\nTimeoutStopSec=10\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></li> <li> <p><code>sudo systemctl daemon-reload</code></p> </li> <li> <p><code>sudo systemctl start vnc.service</code></p> </li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-install-jetsongpio","title":"Let's Install JetsonGPIO","text":"<ol> <li><code>cd /home/ubm</code></li> <li><code>git clone https://github.com/pjueon/JetsonGPIO</code></li> <li><code>cd JetsonGPIO</code></li> <li><code>mkdir build &amp;&amp; cd build</code></li> <li><code>cmake ..</code></li> <li><code>sudo cmake --build . --target install</code></li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-install-sick_scan_xd","title":"Let's Install sick_scan_xd","text":"<ol> <li><code>cd $HOME</code></li> <li><code>cd Software</code></li> <li><code>git clone https://github.com/SICKAG/libsick_ldmrs.git</code></li> <li><code>git clone -b master https://github.com/SICKAG/sick_scan_xd.git</code></li> <li><code>source /opt/ros/foxy/setup.bash</code></li> <li><code>ln -s /home/ubm/Software/libsick_ldmrs/ /home/ubm/f1tenth_ws/src/</code></li> <li><code>ln -s /home/ubm/Software/sick_scan_xd /home/ubm/f1tenth_ws/src/</code> <pre><code>ubm@ubm-bilbo:~$ ls -l /home/ubm/f1tenth_ws/src/\ntotal 0\nlrwxrwxrwx 1 ubm ubm 33 nov 23 14:17 libsick_ldmrs -&gt; /home/ubm/Software/libsick_ldmrs/\nlrwxrwxrwx 1 ubm ubm 31 nov 23 14:18 sick_scan_xd -&gt; /home/ubm/Software/sick_scan_xd\n</code></pre></li> </ol>"},{"location":"guides/SETUP_CAR_FROM_SCRATCH/#lets-build-sick_scan_xd","title":"Let's Build sick_scan_xd","text":"<ol> <li><code>cd ~/f1tenth_ws</code></li> <li><code>sudo apt install ros-foxy-diagnostic-updater</code></li> <li><code>src</code></li> <li><code>colcon build --packages-select libsick_ldmrs --event-handlers console_direct+</code></li> <li><code>src</code></li> <li><code>colcon build --packages-select sick_scan_xd --cmake-args \" -DROS_VERSION=2\" --event-handlers console_direct+</code></li> </ol>"},{"location":"guides/run_real_world_car/","title":"Run Real World Car","text":"<p>This guide provides quick access to all procedures for operating the real-world car. Click on any section to go to the detailed instructions.</p> <p>If you encounter any issues during operation, please refer to the Troubleshooting Guide.</p>"},{"location":"guides/run_real_world_car/#1-checklist","title":"1. Checklist","text":"<ul> <li>Battery Levels</li> <li>Turn on the devices</li> <li>Car Connection</li> <li>Sync the ubm-f1tenth repository</li> </ul>"},{"location":"guides/run_real_world_car/#2-bringup","title":"2. Bringup","text":"<ul> <li>Launch Bringup</li> <li>Controller Connection</li> </ul>"},{"location":"guides/run_real_world_car/#3-mapping","title":"3. Mapping","text":"<ul> <li>Preparation</li> <li>Scan environment</li> <li>Edit the generated map</li> </ul>"},{"location":"guides/run_real_world_car/#4-raceline-speed-profile","title":"4. Raceline &amp; Speed Profile","text":"<ul> <li>Preparation</li> <li>Run the raceline algorithm</li> </ul>"},{"location":"guides/run_real_world_car/#5-run","title":"5. Run","text":"<ul> <li>Preparation</li> <li>Race</li> </ul>"},{"location":"guides/run_real_world_car/#6-shutdown","title":"6. Shutdown","text":""},{"location":"guides/run_real_world_car/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/run_real_world_car/1_CHECKLIST/","title":"Checklists","text":"<ol> <li> <p>Battery Level</p> <p>The battery voltage needs to be between 11.4V and 12.4V in order to preserve their quality over time. To check the battery voltage there are 2 ways</p> <ol> <li>Using a voltmeter</li> <li>Plugging the battery to the charger. There is a section that shows the voltage of each cell.</li> </ol> </li> <li> <p>Turn on the devices</p> <ol> <li>Turn on the router</li> <li>Turn the main power switch of the car to <code>ON</code>, and wait for the car to boot and connect to the network.</li> </ol> <p>Note</p> <p>If the car does not connect to the router or to the correct network, it may be necessary to plug a keyboard and a mouse to the car in order to manually connect it the the right network</p> </li> <li> <p>Car Connection</p> <ul> <li>Connect you computer to the same local network in which the car is connected</li> <li> <p>SSH to the car:</p> <pre><code>ssh ubm@192.168.1.2  # for Philly\nssh ubm@192.168.1.3  # for Ben\n</code></pre> <p>At this point you should see the welcome bash prompt.</p> </li> </ul> <p>Tip</p> <p>Read periodically the welcome bash prompt. You will find there the main commands to use and useful informations.</p> <ul> <li> <p>A VNC server should automatically start, ad you should be able to see the car desktop interface by using a VNC client like tigervnv: Connect by using the IP address of the car and the port <code>5901</code></p> <p>If the VNC server does not automatically start run the following command:</p> <pre><code>vncserver\n</code></pre> </li> </ul> </li> <li> <p>Sync the ubm-f1tenth repository with the desired state</p> <p>To pull the ubm-f1tenth repository an internet connection is needed.</p> <p>Connect the car to the internet</p> <ul> <li>Plug your smartphone to the router with a USB cable</li> <li>Enable USB-tethering on your phone</li> <li>Wait a little and check the car connection by pinging some website.</li> </ul> <pre><code>ping 1.1.1.1\n</code></pre> <p>Note</p> <p>if the car does not connect to internet, it may be necessary to reboot the router.</p> <ul> <li>Once the car is connected to internet it is recommended to sync the github repo</li> </ul> </li> </ol>"},{"location":"guides/run_real_world_car/2_BRINGUP/","title":"Bringup","text":"<p>The bring up command starts the ros2 core nodes.</p> <p>To launch bringup run:</p> <pre><code>launch bringup.py\n</code></pre> <p>Connect the joystick (of the right car) by pressing the PlayStation button.</p> <ul> <li> <p>If the joystick does not connect run</p> <pre><code>connect-controller-philly # to connect to the Philly joystick\nconnect-controller-ben # to connect to the Ben joystick\n</code></pre> </li> </ul> <p>In the logs of the bringup command check for the following line:</p> <p><code>scan=1 connected, joy=1 connected, vesc=1</code></p> <p>If all the 3 are equal to 1 than it means that the car:</p> <ul> <li>it receives the scans from the lidar</li> <li>it is connected to a joystick</li> <li>the vesc is connected and working</li> </ul> <p>The car now can be moved with the joystick:</p> <ul> <li>Hold L1 for slow movement.</li> <li>Hold R1 for fast movement.</li> <li>Use the left stick to control forward and backward motion.</li> <li>Use the right stick to steer the car.</li> </ul> <p>Warning</p> <p>If an issue arises to stop the car immediately press L1 repeatedly.</p> <p>Tip</p> <p>When bringup is running, it is possible to check the battery voltage by running <code>ros2 topic echo /sensors/core/</code>.</p> <p>Important Note: The voltage reading has a bias of approximately +0.2V higher than actual voltage</p>"},{"location":"guides/run_real_world_car/3_MAPPING/","title":"Mapping","text":"<p>The mapping procedure allows to map the track or more in general an environment.</p>"},{"location":"guides/run_real_world_car/3_MAPPING/#preparation","title":"Preparation","text":"<ul> <li> <p>Verify that the bring up is on: Move left and right the wheels of the car a couple of times.</p> </li> <li> <p>Open RViz2: from the VNC instance, open a terminal and run <code>rviz2</code>.</p> <ul> <li>Since we still don't have a map, we won't se anything right away. Thus set fixed frame to <code>laser</code> in order to see the lidar scans. </li> </ul> <p>Note</p> <p>If you don't see the lidar scans or they are stuck move the wheels of the car with the joystick</p> </li> </ul>"},{"location":"guides/run_real_world_car/3_MAPPING/#scan-the-environment","title":"Scan the environment","text":"<ul> <li> <p>Run the mapping algorithm</p> <p>Open a new ssh instance and run</p> <pre><code>launch offline_mapping_closure.py\n</code></pre> <p>From RViz it should be visible that the mapping has started since it starts to build the map.</p> </li> <li> <p>Explore the environment</p> <ul> <li>Move the car slowly around the whole environment. Avoid doing many turns. Less you steer better the mapping will be.</li> <li>When you feel satisfied with the result, keep the car still and do not stop the mapping algorithm because the map needs still to saved.</li> </ul> </li> <li>Save the map<ul> <li>From RViz make sure to have the SLAM toolbox visible. If not open it clicking on \"panels &gt; add new panel &gt; SLAM toolbox plugin\"</li> <li>Next to the <code>Save Map</code> button write the name that you want to give to the map. A suggested name is <code>YYYYMMDD</code></li> <li>Click the <code>Save Map</code> button. In the logs of the mapping algorithm you should see that the map is successfully saved. You should see 2 new files in the folder where the mapping algorithm was executed. One is a <code>.pgm</code> file and one is a <code>.yaml</code> file. Now you can stop the mapping algorithm using <code>CTRL-C</code> in the terminal.</li> <li>A good practice is to move these 2 files in a new folder called <code>YYYYMMDD</code> inside the <code>/home/ubm/repo/maps/</code> directory.</li> </ul> </li> </ul>"},{"location":"guides/run_real_world_car/3_MAPPING/#edit-the-generated-map","title":"Edit the generated map","text":"<p>In order to improve the localization capabilities and supply the speed profile algorithm with an easier map, the map needs to be manually edited.</p> <ol> <li> <p>Copy the map files to your pc:</p> <p>From a terminal in your pc (not in a ssh instance) run the following command, using the right IP address and the correct path.</p> <pre><code>scp -r ubm@&lt;IP-of-the-car&gt;:/home/ubm/repo/maps/YYYYMMDD/ /path/on/your/pc\n</code></pre> </li> <li> <p>Edit the map for localization</p> <ol> <li> <p>Modify the <code>.pgm</code> File     Use an image editor to open the <code>.pgm</code> file. GIMP is recommended for this procedure.</p> <p>Objective: Refine the map to ensure the localization algorithm performs accurately by removing all gray pixels.</p> <ul> <li>All pixels must be either completely black (#000000) or completely white (#FFFFFF).  </li> <li>Avoid making significant changes to the map, as it should closely resemble what the LiDAR scans will detect.</li> </ul> </li> <li> <p>Export the Edited File     Save the edited map as a <code>.pgm</code> file using RAW data formatting. Name the file <code>mapname_edited.pgm</code>.</p> </li> <li> <p>Modify the <code>.yaml</code> File </p> <ul> <li>Copy the <code>.yaml</code> file. </li> <li>Update the <code>image</code> parameter to point to <code>mapname_edited.pgm</code>.  </li> <li>Save the modified file as <code>mapname_edited.yaml</code>.</li> </ul> </li> </ol> <p>Reference Video The video below demonstrates this procedure: </p> <p> </p> </li> <li> <p>Edit the map for raceline</p> <ol> <li> <p>Modify the <code>mapname_edited.pgm</code> File</p> <p>Objective: Refine the map to ensure the raceline algorithm performs accurately by providing a smooth path.</p> <ul> <li>Remove parts of the map where the raceline should not go</li> <li>There must be only a feasible path. If there are obstacles remove all of them. If there are 2 paths to make the lap give the algorithm only one option</li> <li>Make all corners as smooth as possible.</li> <li>Sharp corners may be increased a little to avoid crashes.</li> </ul> </li> <li> <p>Export the Raceline File     Save the edited map as a <code>.pgm</code> file using RAW data formatting. Name the file <code>mapname_raceline.pgm</code>.</p> </li> <li> <p>Modify the <code>.yaml</code> File </p> <ul> <li>Copy the <code>.yaml</code> file.  </li> <li>Update the <code>image</code> parameter to point to <code>mapname_raceline.pgm</code>.  </li> <li>Save the modified file as <code>mapname_raceline.yaml</code>.</li> </ul> </li> </ol> <p>Reference Video The video below demonstrates this procedure: </p> <p> </p> </li> </ol>"},{"location":"guides/run_real_world_car/4_RACELINE/","title":"Raceline &amp; Speed Profile","text":""},{"location":"guides/run_real_world_car/4_RACELINE/#preparation","title":"Preparation","text":"<ul> <li>On you PC, checkout to the default branch of the <code>ubm-f1tenth</code> repository.</li> <li> <p>you should have ready all the following files. If not check Mapping Guide</p> <ul> <li><code>mapname_edited.pgm</code>,</li> <li><code>mapname_edited.yaml</code>,</li> <li><code>mapname_raceline.pgm</code>,</li> <li><code>mapname_raceline.yaml</code></li> </ul> </li> <li> <p>Create a folder within the <code>maps</code> folder called <code>mapname</code> and place all the above files.</p> </li> </ul>"},{"location":"guides/run_real_world_car/4_RACELINE/#run-the-raceline-algorithm","title":"Run the raceline algorithm","text":"<ul> <li>cd to <code>raceline</code> folder</li> <li> <p>Enable the conda environment (make sure to use a bash shell)</p> <pre><code>conda activate raceline\n</code></pre> </li> <li> <p>Execute the raceline algorithm by providing all the necessary parameters:</p> </li> </ul> <p>Usage of the command:</p> <pre><code>$ python raceline.py\n\nusage: raceline.py [-h] -r RACELINE_MAP_PATH [-m LOC_MAP_PATH] [-c CAR_IP]\n                   [--disable_plots] [--invert_direction] [-d DOWNSAMPLE]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -r RACELINE_MAP_PATH, --raceline_map RACELINE_MAP_PATH\n                        The path to the map .pgm file that will be used to\n                        calculate the raceline, expected to be within the\n                        `maps` directory of the repository\n  -m LOC_MAP_PATH, --map_path LOC_MAP_PATH\n                        The path to the map .pgm file that will be used for\n                        localization and gui, expected to be within the `maps`\n                        directory of the repository.Use this option when the\n                        localization map is different from the raceline one.\n  -c CAR_IP, --car_ip CAR_IP\n                        The ip of the car on which the new files will be\n                        uploaded and relative settings will be changed\n  --disable_plots       Disables TUM plots\n  --invert_direction    Invert the direction of the track\n  -d DOWNSAMPLE, --downsample_factor DOWNSAMPLE\n                        The downsample factor to use\n</code></pre> <p>Generally, only the flags -r, -m, and -c are used, while other parameters are omitted. These flags correspond to:</p> <ul> <li>path to <code>mapname_edited.pgm</code>, </li> <li>path to <code>mapname_raceline.pgm</code>,</li> <li><code>&lt;CAR-IP&gt;</code>:</li> </ul> <p>Follow the terminal instructions. The raceline and speed profile will be computed. If you provided the ip of the car then it will ask you to upload the results to the car.</p> <p>By accepting, the car will receive the map and the raceline, and it will be ready to run all the algorithms that require maps and localization!</p>"},{"location":"guides/run_real_world_car/5_RUN/","title":"Run","text":""},{"location":"guides/run_real_world_car/5_RUN/#preparation","title":"Preparation","text":"<ul> <li> <p>Verify that the correct map and speed profile is loaded</p> <pre><code>cat launch/config/launch_config.yaml\n</code></pre> <p>If not, execute the <code>update_settings.py</code> located in the root of the repository providing all necessary parameters.</p> <pre><code>$ python update_settings.py -h\n\nusage: update_settings.py [-h] -m MAP_PATH [-y YAML_PATH] -r RACELINE_FILE -b BOUNDARIES_FILE\n\noptions:\n-h, --help            show this help message and exit\n-m MAP_PATH, --map_path MAP_PATH\n                        The path to the map .pgm file, expected to be within the `maps` directory of the repository\n-y YAML_PATH, --map_yaml_path YAML_PATH\n                        The path to the map .yaml file, expected to be within the `maps` directory of the repository. If omitted assumed to be MAP_PATH with `.yaml` extension.\n-r RACELINE_FILE, --raceline RACELINE_FILE\n                        The name of the raceline .csv file, expected to be within the `raceline/csv/TUM_raceline` directory of the repository\n-b BOUNDARIES_FILE, --boundaries BOUNDARIES_FILE\n                        The name the boundaries .csv file, expected to be within the `raceline/csv/TUM_raceline` directory of the repository  \n</code></pre> </li> <li> <p>Stop bringup, and every other running node.</p> </li> <li>From VNC close RViz</li> </ul>"},{"location":"guides/run_real_world_car/5_RUN/#race","title":"Race","text":"<ol> <li> <p>Run Bringup</p> <p>Follow bringup guide</p> </li> <li> <p>Open RViz</p> <p>From the VNC instance, open a terminal and run <code>rviz2</code>.</p> </li> <li> <p>Localize the car</p> <p>To start the localization algorithm open a new ssh instance and run run:</p> <pre><code>launch localize_launch_mit.py\n</code></pre> <p>The map should pop up in RViz.</p> <p>Use <code>2D pose estimate</code> in RViz to place the car in the correct location.</p> </li> <li> <p>Launch control node and race!</p> <p>To start the control stack open a new ssh instance and run:</p> <pre><code>launch control.py\n</code></pre> <p>The raceline should pop up in RViz.</p> <p>You can now press one of button of the joystick to run a control algorithm.</p> Symbol Algorithm Cross Disparity Extender Circle Pure Pursuit Triangle Potential Field Square Potential Pursuit L1 or R1 STOP </li> </ol>"},{"location":"guides/run_real_world_car/6_SHUTDOWN/","title":"Shutdown","text":"<p>To shutdown properly the car:</p> <ol> <li>Stop each algorithm running using <code>CTRL-C</code> to each ssh session</li> <li>Close/Save all open files</li> <li>push relevant changes to github (a.e. a new map)</li> <li>Execute <code>sudo poweroff</code> and wait some time. At least until the fan stops spinning.</li> <li>Turn the main power switch of the car to <code>OFF</code></li> <li>Unplug the battery</li> </ol> <p>For the router is sufficient to press the power button and to unplug it.</p>"},{"location":"guides/run_real_world_car/TROUBLESHOOTING/","title":"Troubleshooting","text":"<p>This guide provides solutions for common issues and important checks during operation.</p>"},{"location":"guides/run_real_world_car/TROUBLESHOOTING/#missing-or-outdated-build-artifacts","title":"Missing or Outdated Build Artifacts","text":"<p>Symptoms:</p> <ul> <li>Node execution fails</li> <li>Missing executables or libraries.</li> </ul> <p>Solution:</p> <ol> <li> <p>Rebuild and source the workspace</p> <pre><code>rebuild_ws\nsrc\n</code></pre> </li> </ol>"},{"location":"guides/run_real_world_car/TROUBLESHOOTING/#incorrect-environment-setup","title":"Incorrect Environment Setup","text":"<p>Symptoms:</p> <ul> <li>Missing packages or commands</li> <li>Errors related to sourcing or dependencies</li> </ul> <p>Solution:</p> <ol> <li> <p>Source the environment</p> <pre><code>src\n</code></pre> </li> <li> <p>Verify if the required package exists in the <code>~/f1tenth_ws/src</code> directory:</p> <pre><code>ls ~/f1tenth_ws/src\n</code></pre> <p>If the package is missing, create a symbolic link to the package location and build the workspace.</p> <pre><code>ln -s /path/to/package ~/f1tenth_ws/src/\nbuild_ws\n</code></pre> </li> </ol>"},{"location":"guides/run_real_world_car/TROUBLESHOOTING/#localization-or-mapping-issues","title":"Localization or Mapping Issues","text":"<p>Symptoms:</p> <ul> <li>Localization or mapping does not work.</li> <li>Nodes or RViz fail to display map or lidar scans.</li> </ul> <p>Solution:</p> <ol> <li>Kill all running nodes except the bringup node.</li> <li>Close RViz and open it again before running other nodes.</li> </ol> <p>If the issue persists</p> <ol> <li>Kill all running nodes included the bringup node.</li> <li>Close RViz and open it again before running other nodes.</li> </ol> <p>If the issue still persists</p> <ol> <li> <p>Kill all running nodes and reboot the car</p> <pre><code>sudo reboot\n</code></pre> </li> <li> <p>Restart the modem/router</p> </li> </ol> <p>If none of the above works</p> <ul> <li>Enjoy debugging \ud83d\ude07</li> </ul>"},{"location":"setup/","title":"Setup","text":"<p>In this section you can find all the build and setup instructions of our tools.</p>"},{"location":"setup/DOCS_GENERATION/","title":"Documentation Generation","text":""},{"location":"setup/DOCS_GENERATION/#introduction","title":"Introduction","text":"<p>This guide explains how documentation generation is configured and works in the <code>ubm-f1tenth</code> repository.</p>"},{"location":"setup/DOCS_GENERATION/#overview","title":"Overview","text":"<p>The repository uses a combination of tools for generating documentation:</p> <ul> <li>MkDocs: For managing the overall documentation website.</li> <li>MkDocstrings: To parse Python docstrings and generate reference pages.</li> <li>rosdoc2: To generate C++ package documentation using Doxygen and Sphinx.</li> </ul> <p>The whole process is automatized with the use of GitHub Actions.</p>"},{"location":"setup/DOCS_GENERATION/#deployment-with-github-actions","title":"Deployment with GitHub Actions","text":"<p>The CI/CD workflow automates the process of building and deploying documentation to GitHub Pages. The key steps in <code>.github/workflows/ci.yml</code> are:</p> <ol> <li> <p>Clone ubm-f1tenth Repository</p> </li> <li> <p>Generate C++ Documentation:</p> <ul> <li>Uses rosdoc2 to generate documentation for C++ packages found in the repository.</li> <li>The script searches for package.xml files in the ubm-f1tenth directory and identifies packages that use rosdoc2.</li> <li>For each identified package, it runs rosdoc2 build to generate HTML documentation, which is stored in a specified output directory.</li> <li>A markdown file (CPP_PACKAGES.md) is created listing the packages with links to their generated documentation.</li> </ul> </li> <li> <p>Move Python packages to src:</p> <ul> <li>Copies Python packages found within the repository into the <code>src/</code> folder to prepare them for MkDocs documentation generation. This is done by checking for the presence of ament_python in each package.xml file.</li> </ul> </li> <li> <p>Build Documentation:</p> <ul> <li>Runs MkDocs to generate static documentation from the source files.</li> <li>All the configs are set in the <code>mkdocs.yaml</code> file.</li> <li><code>mkdocs build</code> clears the content of the <code>site/</code> directory, builds the content inside the <code>docs/</code> directory and processes with mkdocstrings the source code present in <code>src/</code> directory. The output will be in the <code>site</code> directory.</li> <li>Custom navigation is generated dynamically based on Python module structure by the <code>gen_ref_pages.py</code> present in the script/ folder.</li> </ul> </li> <li> <p>Add Additional Files to Site:</p> <ul> <li>Copies the generated C++ documentation to the <code>site</code> directory for deployment.</li> </ul> </li> <li> <p>Deploy with ghp-import:</p> <ul> <li>Deploys the content of <code>site/</code> to GitHub Pages using the <code>ghp-import</code> tool.</li> </ul> <p>Danger</p> <p><code>ghp-import</code> will DESTROY the gh-pages branch. This script assumes that gh-pages is 100% derivative. You should never edit files in your gh-pages branch by hand because you will lose your work.</p> </li> </ol> <p>Warning</p> <p>Make sure that informations that are not meant to be public are not included in the ./docs folder or ./site folder The workflow will make the content of the ./docs folder and ./site folder public.</p>"},{"location":"setup/SETUP/","title":"Setup of the \"ubm-f1tenth\" environment","text":""},{"location":"setup/SETUP/#linuxmac","title":"Linux/Mac","text":"<p>Install Foxglove studio here and create an account.</p> <p>To remove the corrupted configs and restore the docker CLI config to default Run the following command: <pre><code>sudo rm ~/.docker/config.json\n</code></pre> Now clone the repository and enter its folder. To obtain the docker image you can pull it from our dockerhub account, first login with: <pre><code>docker login -u ubmdriverless -p &lt;redacted&gt;\n</code></pre> then to pull: <pre><code>docker pull ubmdriverless/f1tenth:latest\n</code></pre> Alternatively you can build the image yourself with: <pre><code>docker build -t f1tenth-ubm-sim -f Dockerfile .\n</code></pre> This will take a long time, around 10-30 minutes. You only have to do it once! Now start the docker container. <pre><code>docker compose up\n</code></pre> And in as many other terminals as you want to access the simulation run:  <pre><code>docker exec -it ubm-f1tenth-sim-1 /bin/bash\n</code></pre> In one of these terminals bring up the simulation: <pre><code>launch sim.py\n</code></pre> This command will launch the simulator and open a websocket at <code>ws://localhost:9090</code></p> <p>Now that the simulator is up, you can see it by connecting to the websocket at <code>localhost:9090</code>. Open Foxglove studio, log in and select <code>Open connection...</code> on the left panel. Then select <code>Rosbridge</code> in the popup window and make sure that the address is <code>ws://localhost:9090</code>, then click <code>Open</code>.</p> <p>The main window is the <code>3D Panel</code>, here you will see a 3D rendering of the data being published by ROS. To view the car click on the 3D panel, then on <code>Panel</code> in the left side-bar, here you can select which topics to view, make sure that <code>Display frame</code> is set to <code>map</code>, then scroll down to <code>Custom layers</code> and click on the three dots to add a <code>URDF</code> (this will be the 3D model of the car), in the URDF settings select <code>Topic</code> as source and <code>/ego_robot_description</code> in the <code>Topic</code> value.</p> <p>If you are seeing a bunch text and arrows on top of the car, those are the car's transforms, you can hide them in the <code>Transforms</code> section.</p> <p>Setting the <code>Color by</code> value of the <code>/scan</code> topic to <code>range</code> is advised.</p> <p>For more info on how Foxglove works refer to the official documentation.</p> <p>You will see the car and the track! In another one of the Visual Studio Code terminals start up the control stack: <pre><code>launch control.py\n</code></pre> In another one of these terminals send virtual telecommand signals: <pre><code>press_circle\n</code></pre> This starts the pure pursuit algorithm and the car will move. The telecommand to stop the car is: <pre><code>press_L1\n</code></pre> To shut it down, go to the first terminal, the one you started the container with \"docker compose up\" and press ^C. Next time you wish to code, open VSCode in the correct directory, start docker and connect with Tiger VNC.</p>"},{"location":"setup/SETUP/#windows","title":"Windows","text":"<p>For compatibility, it runs within WSL. This is a linux virtual machine provided by Microsoft that runs with near bare metal performance. Open a powershell prompt and install WSL: <pre><code>wsl --install\n</code></pre> To make sure wsl uses Ubuntu as the default distribution: <pre><code>wsl -s Ubuntu\n</code></pre> Now open wsl by typing: <pre><code>wsl\n</code></pre> By default, you are put in a mount on your C: drive. For read/write performance, we will create a folder in your linux home. <pre><code>cd ~\nmkdir  F1Tenth\ncd F1Tenth\n</code></pre> Now we set up github to clone the repository in this directory using SSH keys, since passwords are deprecated. <pre><code>ssh-keygen -t ed25519 -C \"your_email@example.com\"\n</code></pre> Press enter to accept the default file location. Set a password. Copy your SSH key: <pre><code>cat ~/.ssh/id_ed25519.pub\n</code></pre> Go to https://github.com/settings/ssh/new and name your key, then paste it and click \"Add SSH key\". Now you can clone the repo: <pre><code>git@github.com:ubm-driverless/ubm-f1tenth.git\n</code></pre> Install Foxglove here and create an account.</p> <p>Do not close the powershell but go back to your Windows desktop, we have Docker Desktop and Visual Studio Code to install: https://docs.docker.com/desktop/install/windows-install/  https://code.visualstudio.com/download Open Docker Desktop, go to general settings and ensure that \"Use the WSL 2 based engine\" is checked. Go back to your powershell. Navigate inside the repo and open it in Visual Studio code. <pre><code>cd ubm-f1tenth/\ncode .\n</code></pre> This is your development enviroment. Cool! Now to install ROS2 in a docker container, use a new terminal within Visual Studio Code. This ensures it is the correct directory and also in WSL. It's perfectly fine to run this in a new terminal if the vs code one is not working. It might be solved by rebooting.</p> <p>To obtain the docker image you can pull it from our dockerhub account, first login with: <pre><code>docker login -u ubmdriverless -p &lt;redacted&gt;\n</code></pre> then to pull: <pre><code>docker pull ubmdriverless/f1tenth:latest\n</code></pre> Alternatively you can build the image yourself with: <pre><code>docker build -t f1tenth-ubm-sim -f Dockerfile .\n</code></pre> This will take a long time, around 10-30 minutes. You only have to do it once! Now start the docker container.</p> <p>Now start the docker container. <pre><code>docker compose up\n</code></pre> And in as many other terminals as you want to access the simulation:  <pre><code>docker exec -it ubm-f1tenth-sim-1 /bin/bash\n</code></pre> In one of these terminals bring up the simulation: <pre><code>launch sim.py\n</code></pre> This command will launch the simulator and open a websocket at <code>ws://localhost:9090</code></p> <p>Now that the simulator is up, you can see it by connecting to the websocket at <code>localhost:9090</code>. Open Foxglove studio, log in and select <code>Open connection...</code> on the left panel. Then select <code>Rosbridge</code> in the popup window and make sure that the address is <code>ws://localhost:9090</code>, then click <code>Open</code>.</p> <p>The main window is the <code>3D Panel</code>, here you will see a 3D rendering of the data being published by ROS. To view the car click on the 3D panel, then on <code>Panel</code> in the left side-bar, here you can select which topics to view, make sure that <code>Display frame</code> is set to <code>map</code>, then scroll down to <code>Custom layers</code> and click on the three dots to add a <code>URDF</code> (this will be the 3D model of the car), in the URDF settings select <code>Topic</code> as source and <code>/ego_robot_description</code> in the <code>Topic</code> value.</p> <p>If you are seeing a bunch text and arrows on top of the car, those are the car's transforms, you can hide them in the <code>Transforms</code> section.</p> <p>Setting the <code>Color by</code> value of the <code>/scan</code> topic to <code>range</code> is advised.</p> <p>For more info on how Foxglove works refer to the official documentation.</p> <p>You will see the car and the track! In another one of the Visual Studio Code terminals start up the control stack: <pre><code>launch control.py\n</code></pre> In another one of these terminals send virtual telecommand signals: <pre><code>press_circle\n</code></pre> This starts the pure pursuit algorithm and the car will move. The telecommand to stop the car is: <pre><code>press_L1\n</code></pre> To shut it down, go to the first terminal, the one you started the container with \"docker compose up\" and press ^C. Next time you wish to code, start WSL, open VSCode in the correct directory, start docker and connect with Tiger VNC.</p>"},{"location":"setup/SETUP/#useful-information","title":"Useful Information","text":""},{"location":"setup/SETUP/#when-to-use-colcon-build","title":"When to Use <code>colcon build</code>","text":"<ul> <li>After Cloning a New ROS2 Package or Project: If you\u2019ve cloned a new ROS2 package or project into your workspace, run <code>colcon build</code> to compile it.</li> <li>After Modifying Code or Configuration Files: If you make changes to source code or configuration files, you need to recompile using <code>colcon build</code>.</li> <li>After Modifying CMakeLists.txt or package.xml: Any changes to these files require recompilation.</li> <li>When Adding New Dependencies: If you add new dependencies, use <code>colcon build</code> to update them.</li> <li>To Perform a Clean Build: Use <code>colcon build --cmake-clean-cache</code> to remove the CMake cache and rebuild from scratch.</li> </ul>"},{"location":"setup/SETUP/#command","title":"Command:","text":"<p>colcon build</p>"},{"location":"setup/SETUP/#useful-options","title":"Useful Options:","text":"<ul> <li><code>--packages-select &lt;package_name&gt;</code>: to compile only a specific package.</li> </ul>"},{"location":"setup/SETUP/#additional-notes","title":"Additional Notes","text":"<ul> <li> <p>Rebuild Docker Environment: Rebuild the environment only if modifications are made to the <code>Dockerfile</code>.</p> </li> <li> <p>Change Map: To change the map used in the simulation, modify the <code>sim.yaml</code> file located in the <code>f1_tenth_gym_ros</code> directory.</p> </li> <li> <p>Control and Speed Profiles: </p> </li> <li>Modify <code>control.py</code> only in the <code>TUM_node</code>.</li> <li>Create a speed profile (only if it doesn't exist already).</li> <li>Adjust lines 21 and 22 in <code>raceline.py</code> if needed.</li> </ul> <p>When changing a map change: control.py, raceline.py, f1_tenth_gym_ros/config/sim_yaml, launch_config.yaml</p>"}]}